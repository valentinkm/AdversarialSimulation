---
title: "Adversarial Simulation"
subtitle: "Structural after Measurement vs. standard SEM estimation - a Case Study on Adversarial Collaboration for Simulation Studies"
fig-cap-location: top
author: 
  - name: "Valentin Kriegmair"
format:
  revealjs:
    center: true
    theme: default
    slide-number: c/t
    font-size: 12pt
    chalkboard: true

engine: knitr
bibliography: ../bibliography.bib
csl: ../apa.csl
---

```{r, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = FALSE)
library(dplyr)
library(tidyr)
library(kableExtra)
library(ggplot2)
```

::: {.r-fit-text style="font-size: 0.8em;"}

## Outline {auto-animate="true"}

1.  The Generalizability Challenge & Adversarial Collaboration

2.  An Adversarial Simulation Framework

3.  Background (SAM vs. SEM)

4.  Results & Evaluation

5.  Personal Fit to the Project

::: notes
Good afternoon, everyone. Thank you for having me here. I’m Valentin Kriegmair, a master’s student at Humboldt University. I will present my masters thesis project conducted in collaboration with Leonard Kosanke and supervised by Aaron Peikert and Mathias Ziegler. Our work explores how the practice of adversarial collaboration originally developed to tackle persistent scientific disagreements can be applied to simulation studies. We tested this approach by comparing a method called Structural After Measurement (SAM) with traditional Structural Equation Model (SEM) estimation techniques.
:::
:::

## The Generalizability Challenge {auto-animate="true"}

::: columns
::: {.column width="0%"}
::: r-fit-text
<br> <br> <br> <br> <br> <br> <br> <br> <br>
:::
:::

::: {.column width="50%"}
::: r-fit-text
```{dot}
digraph circular_process {
    // Use 'neato' layout for positioning
    layout=neato;
    overlap=false;
    splines=true;

    // Define global node attributes
    node [shape=plaintext, fontsize=12];

    // Define nodes with positions to form a circle
    hypothesize [label="Hypothesize", pos="0,1!"];
    operationalize [label="Operationalize", pos="-0.866,-0.5!"];
    gather_data [label="Gather Data", pos="0.866,-0.5!"];

    // Define edges to create a circular process
    hypothesize -> operationalize;
    operationalize -> gather_data;
    gather_data -> hypothesize;
}
```
:::
:::
:::

::: notes
Karl Popper once famously described Science as the art of "systematic over simplification". This term ironically and yet accurately describes the very basic cycle of empirical research, where we lay out general claims about the world as hypotheses, translate them into measurable constructs and choose how to gather data from certain populations that finally in turn updates our beliefs in general verbal claims about the world.
:::


## The Generalizability Challenge {auto-animate="true" auto-animate-easing="ease-in-out"}

::: columns
::: {.column width="25%"}
::: r-fit-text
<br> [general & verbal]{style="color:blue"} <br> <br> <br> <br>

::: fragment
[researcher's degrees of freedom]{style="color: red;"} <br>
:::

::: fragment
[→ ambiguity]{style="color: red;"} <br> [→ **persistent disagreement**]{style="color: red;"}
:::

<br> <br> <br> [specific]{style="color: green;"} & [ empirical]{style="color: purple"}
:::
:::

::: {.column width="50%"}
::: r-fit-text
```{dot}
digraph circular_process {
    // Use 'neato' layout for positioning
    layout=neato;
    overlap=false;
    splines=true;

    // Define global node attributes
    node [shape=plaintext, fontsize=12];

    // Define nodes with positions to form a circle
        hypothesize [label=< <font color="blue">Hypothesize</font> >, pos="0,1!"];
        operationalize [label=< <font color="green">Operationalize</font> >, pos="-0.866,-0.5!"];
        gather_data [label=< <font color="purple">Gather Data</font> >, pos="0.866,-0.5!"];

    // Define edges to create a circular process
    hypothesize -> operationalize [color="red"];
    operationalize -> gather_data [color="red"];
    gather_data -> hypothesize [color="red"];
}
```
:::
:::
:::

::: notes
One core challenge in every research endavour is the mapping of the general to the specific (when designing and conducting the study) or from the specific & empirical to the verbal & general (when interpreting the results) 
(▶︎). This mapping seems the crux of most research and here most, if not all of of a researcher's degrees of freedom lie. (▶︎) This makes this mapping the source of ambiguity and persistant disputes. When divergences in mappings from the verbal plane are not recognized or not transparent, persistent and seemingly unresolvable disagreements in the general and verbal plane occur.
:::

## The Generalizability Challenge {auto-animate="true" auto-animate-easing="ease-in-out"}

In Simulation Studies

::: columns
::: {.column width="25%"}
::: r-fit-text
<br> [general & verbal]{style="color:blue"} <br> <br> <br> <br> [researchers degrees of freedom]{style="color: red;"} <br> [→ ambiguity]{style="color: red;"} <br>

::: {data-id="text1" auto-animate-delay="0"}
[→ **persistant disagreement**]{style="color: red;"}
:::

<br> <br> <br> <br> [specific]{style="color: green;"} & [ empirical]{style="color: purple"}
:::
:::

::: {.column width="50%"}
::: r-fit-text
```{dot}
digraph circular_process {
    // Use 'neato' layout for positioning
    layout=neato;
    overlap=false;
    splines=true;

    // Define global node attributes
    node [shape=plaintext, fontsize=12];

    // Define nodes with positions to form a circle
    hypothesize [label=< <font color="blue">Method A vs. B</font> >, pos="0,1!"];
    operationalize [label=<
        <table border="0" cellborder="0" cellspacing="0">
            <tr><td><font color="green">Model,<br/> Estimands,<br/> Metrics etc.</font></td></tr>
        </table>
    >, pos="-0.866,-0.5!", color="green"];
    gather_data [label=< <font color="purple">Simulate</font> >, pos="0.866,-0.5!", color="green"];

    // Define edges to create a circular process
    hypothesize -> operationalize [color="red"];
    operationalize -> gather_data [color="red"];
    gather_data -> hypothesize [color="red"];
}
```
:::
:::
:::

::: notes
This challenge transfers to monte carlo simulation studies. These are commonly used tools to test statistical methods in simulated data that can be used to evaluate any method against a known ground truth. Researchers must decide which “prototypical” data and models to use. These decisions, influenced by prior beliefs and methodological preferences, can lead to persistent disagreements. For instance, two researchers might compare different methods under slightly different simulation conditions, each concluding their preferred method is superior.
:::

## Adversarial Collaboration (AC) as a Remedy? {auto-animate="true" auto-animate-easing="ease-in-out"}

::: r-fit-text
Pioneered by @mellers_frequency_2001: ![](figures/paper1.png){width="70%"}

Recognized in Empirical Research @melloni_adversarial_2023 @clark_adversarial_2021
:::

::: notes
Adversarial Collaboration is a scientific practice that aimed to tackle entrenched disagreeing positions and unveil underlying discrepancies in operationalizations.
It was famously pioneered by Ralph Hertwig and Daniel Kahneman who tried to settle a persistent scientific disagreement about frequency representation and consulted Barbara Mellers as a neutral arbiter.
Today it is recognized as a potent tool in the social empirical research community
:::

## Adversarial Collaboration (AC) {auto-animate="true" auto-animate-easing="ease-in-out"}

::: columns
::: {.column width="25%"}
::: r-fit-text
::: {.fragment fragment-index="1"}
<br> [Identify general & verbal Disagreement → joint Research Question]{style="color:blue"} <br>
:::

::: {.fragment fragment-index="2"}
<span style="color: red;">Agree on: <br> - Operationalizations <br> - Test Design <br> - Interpretation
:::

::: {.fragment fragment-index="3"}
</span> [→ Reduce ambiguity<br>→ Increase generalizability ]{style="color: black;"}
:::

<br>

::: {.fragment fragment-index="2"}
[unify]{style="color: green;"}
:::
:::
:::

::: {.column width="50%"}
::: r-fit-text
```{dot}
digraph circular_process {
    // Use 'neato' layout for positioning
    layout=neato;
    overlap=false;
    splines=true;

    // Define global node attributes
    node [shape=plaintext, fontsize=12];

    // Define nodes with positions to form a circle
    hypothesize [label=< <font color="blue">Verbal Dispute</font> >, pos="0,1!"];
    operationalize [label=< <font color="green">Operationalizations</font> >, pos="-0.866,-0.5!", color="green"];
    gather_data [label=< <font color="green">Gather Data</font> >, pos="0.866,-0.5!", color="green"];

    // Define edges to create a circular process
    hypothesize -> operationalize [color="red"];
    operationalize -> gather_data [color="red"];
    gather_data -> hypothesize [color="red"];
}
```
:::
:::
:::

::: notes
The basic idea is for two researchers in disagreement to first identify a general verbal dispute and agree on a research question to settle the debate. (▶︎)
Based on this they collaboratively work on operationalizing, testing and interpreting this verbal claim. (▶︎)
This process aims to unveil and concretize underlying disagreements and thus reduce ambiguity and increase generalizability. (▶︎)
:::

## Creating an Adversarial Simulation [Framework]{style="color:#4682B4;"} {auto-animate="true"}

::: notes
To conduct such an exemplary adversarial collaboration, we first need a framework that structures the collaborative process tailored to the outline of simulation studies.
:::

## A [Structured]{style="color:#4682B4;"} Adversarial Simulation [Framework]{style="color:#4682B4;"} {auto-animate="true"}

::: r-fit-text
+-------------------------+----------------+------------------------------+----------------+
|                         | Round 1        | Round 2                      | Round 1        |
+=========================+:==============:+:============================:+:==============:+
| Steps                   | Collaborator 1 | Joint Study                  | Collaborator 2 |
+-------------------------+----------------+------------------------------+----------------+
| 1\. Research Question   |                | Agreed upon prior to Round 1 |                |
+-------------------------+----------------+------------------------------+----------------+
| 2\. Population Model    | →              |                              | ←              |
+-------------------------+----------------+------------------------------+----------------+
| 3\. Data Generation     | →              |                              | ←              |
+-------------------------+----------------+------------------------------+----------------+
| 4\. Experimental Design | →              |                              | ←              |
+-------------------------+----------------+------------------------------+----------------+
| 5\. Method Selection    | →              |                              | ←              |
+-------------------------+----------------+------------------------------+----------------+
| 6\. Estimands           | →              |                              | ←              |
+-------------------------+----------------+------------------------------+----------------+
| 7\. Performance Metrics | →              |                              | ←              |
+-------------------------+----------------+------------------------------+----------------+
| 8\. Software            | →              |                              | ←              |
+-------------------------+----------------+------------------------------+----------------+
| 9\. Analysis            | →              |                              | ←              |
+-------------------------+----------------+------------------------------+----------------+
:::

::: notes
We developed a specific adversarial simulation framework and structured the collaboration into two rounds. In the first round, each collaborator independently conducts a separate simulation study. In the second round, they come together to work on a joint study, building on the findings from the first round.

This two-step approach is designed to highlight differences in a systematic way and to establish an virtual foundation for collaboration before engaging in a joint effort in our case study.
:::

## Structural after Measurement (SAM) vs traditional SEM estimation [ Background]{style="font-size: 20px;"}

::: notes
Now, to set the stage for our specific case study, I briefly outline the background of the case we applied our adversarial simulation framework to: Structural After Measurement (SAM) vs. traditional Structural Equation Model (SEM) estimation.
:::

## Standard SEM Estimation [(e.g.ML, ADF, GLS, ULS)]{style="font-size: 20px;"} {auto-animate="true"}

::: columns
::: {.column width="50%"}
![](figures/model0.svg){width="100%"}
:::

::: {.column width="50%"}
::: r-fit-text
::: {.fragment .fade-in-then-out}
-   e.g. normal theory-based maximum likelihood (ML) discrepancy function
-   System-wide parameter ($\vartheta$) optimization
-   Assumes multivariate normal distribution
:::

::: {.fragment .fade-in}
Problems:

-   non-convergence issues
-   improper solutions
-   bias due to local measurement misspecifications propagating to all model parameters
-   requiring large sample sizes for optimal statistical properties.
:::
:::
:::
:::

::: notes
Traditional SEM methods, like maximum likelihood estimation, optimize all parameters of a model simultaneously under the assumption of multivariate normality. While powerful and although robust estimation techniques relax the normality assumption, all system wide estimators suffer from several shortcomings, \[▶︎\] they often face issues such as non-convergence, improper solutions (with parameters out of definitional range), and biases from local measurement misspecifications that affect the entire model.
:::

## Structural After Measurement (SAM)

::: columns
::: {.column width="50%"}
<img src="figures/model0_1.svg" width="80%"/>
:::

::: {.column width="50%"}
::: r-fit-text
**Two-phase process:**

1.  [$\vartheta_1$: Measurement model]{style="color: red;"} <br> [**Local SAM (lSAM):**]{.fragment} <br> [Separate "measurement blocks"]{.fragment}<br> [Latent summary statistics and mapping matrix;]{.fragment} <br> [**Global SAM (gSAM):** Fixed measurement parameters for the entire measurement model.]{.fragment}

::: fragment
<br> → <br>
:::

2.  [$\vartheta_2$: Structural model]{style="color: blue;"}
:::
:::
:::

@rosseel_structural_2022

::: notes
SAM addresses some limitations of SEM by separating the estimation into two phases. First, the measurement model parameters are estimated and then fixed to estimate the structural model. This approach aims to reduce the propagation of bias from the measurement to the structural part and decrease convergence issues, especially in smaller samples and complex models. \[▶︎\] There are two distinctive implementations of SAM \[▶︎\] local SAM constructs latent variable summary statistics and a mapping matrix to inform the structural model estimation, \[▶︎\] while global SAM directly estimates structural parameters using fixed measurement parameters of one measurement model.\[▶︎\]
:::

## SAM vs. SEM: <br> Disagreeing Reports {auto-animate="true"}

::: r-fit-text
+-----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| @rosseel_structural_2022, @dhaene_evaluation_2023                                                                                             | @robitzsch_comparing_2022                                                                                                                                                                                      |
+===============================================================================================================================================+================================================================================================================================================================================================================+
| \- SAM outperformed SEM in terms of convergence, bias & RMSE in small samples x low item reliability, especially under misspecifications <br> | \- SAM did not generally outperform traditional SEM in challenging conditions. <br> - SAM appears better: general negative small sample bias of SAM cancels out positive bias from positive misspecifications. |
+-----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

<br> <br>

::: fragment
::: {style="text-align: center;"}
**→ Basis for a case study on adversarial collaboration**
:::
:::

::: notes
Since SAM was recently reintroduced as a potential alternative to traditional SEM estimation, there have been conflicting reports on its performance. Rossel, Loh and Dahene found in two simulation studies that SAM outperformed SEM in terms of convergence, bias, and RMSE, particularly in small samples with low item reliability, especially under misspecifications. In contrast there was a study by Robitzsch that found that SAM did not generally outperform traditional SEM in challenging conditions. He argued that SAM only appears better in specific conditions because a general negative small sample bias of SAM cancels out the positive bias from positive misspecifications.\[▶︎\] This disagreement formed the basis for our adversarial simulation case study
:::
:::

## SAM vs. SEM: <br> an [ Adversarial Simulation ]{style="color: #4682B4;"} {auto-animate="true"}

::: r-fit-text
+-----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| @rosseel_structural_2022, @dhaene_evaluation_2023                                                                                             | @robitzsch_comparing_2022                                                                                                                                                                                      |
+===============================================================================================================================================+================================================================================================================================================================================================================+
| \- SAM outperformed SEM in terms of convergence, bias & RMSE in small samples x low item reliability, especially under misspecifications <br> | \- SAM did not generally outperform traditional SEM in challenging conditions. <br> - SAM appears better: general negative small sample bias of SAM cancels out positive bias from positive misspecifications. |
+-----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| [**Replication by Kriegmair**]{style="color: #4682B4;"}                                                                                       | [**Replication by Kosanke**]{style="color: #4682B4;"}                                                                                                                                                          |
+-----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

<br> <br>

::: {style="text-align: center;"}
**→ Basis for a case study on adversarial collaboration**
:::
:::

::: notes
A conceptual replication of these studies based on a joint research question was conducted by Leonard Kosanke and myself as round 1 of our collaboration.
:::

## Research Questions

::: r-fit-text
**Is Adversarial Collaboration a viable approach to address ambiguity and increase generalizability in simulation studies?** <br> <br> **Substantive Questions wihtin the Case Study** [(agreed upon prior to individual studies)]{style="font-size: 20px;"}

1.  How do SAM and traditional SEM methods (including ML and ULS) compare in terms of bias, Mean Squared Error (MSE), and convergence rates in small to moderate samples?
2.  What is the impact of model misspecifications, such as residual correlations and cross-loadings, on the performance of SAM compared to traditional SEM methods?
:::

::: notes
Our primary research question is whether adversarial collaboration is a viable approach to reduce ambiguity and increase generalizability in simulation studies. Specifically, within our case study, we want to compare SAM and traditional SEM methods in terms of bias, MSE, and convergence rates in small to moderate samples, and assess the impact of model misspecifications on their performance.
:::

## Findings of the Case Study

Replication Results <br> Adversarial Collaboration

::: notes
Now, let's delve into the results of our case study.
:::

## Round 1: Individual Studies

+---------------------------------------------------------------+------------------------------------+
| Kriegmair                                                     | Kosanke                            |
+===============================================================+====================================+
| based on @rosseel_structural_2022 and @dhaene_evaluation_2023 | based on @robitzsch_comparing_2022 |
+---------------------------------------------------------------+------------------------------------+

::: notes
As mentioned earlier, in the first round of our adversarial collaboration, Leonard Kosanke and I conducted individual simulation studies based on the conflicting reports by Rossel, Loh, and Dahene, as well as Robitzsch.
:::

## Studies by Kriegmair [based on @rosseel_structural_2022]{style="font-size: 20px;"}

::: r-fit-text
::: {layout="[20,60,20]"}
::: {.column width="0%"}
:::

::: {.column width="60%"}
::: {layout="[[1,1], [1,1]]" layout-valign="top"}
::: {.column width="50%"}
1.1 [no misspecifications]{style="font-size: 20px;"} ![](figures/model1_1.svg){width="60%"}
:::

::: {.column width="50%"}
1.2 [ cross loadings]{style="font-size: 20px;"} ![](figures/model1_2.svg){width="60%"}
:::

::: {.column width="50%"}
1.3 [ correlated residuals ]{style="font-size: 20px;"} ![](figures/model1_3.svg){width="80%"}
:::

::: {.column width="50%"}
1.4 [ structural misspecification ]{style="font-size: 20px;"} ![](figures/model1_4.svg){width="60%"}
:::
:::
:::

::: {.column width="35%"}
#### Other Conditions:

-   *N*: 100, 400, 6400
-   Indicator reliability: 0.3, 0.5, 0.7



#### Methods:

-   Standard SEM with Maximum Likelihood (ML)
-   Global SAM (gSAM)
-   Local SAM (lSAM-ML)
-   Local SAM with unweighted least squares (lSAM-ULS)



#### Performance Metrics:

-   Bias $\hat{\beta}_i - \beta_i$
-   RMSE $\sqrt{\sum_{i=1}^{n} (\hat{\beta}_i - \beta_i)^2}$
-   Coverage of 95% CI
:::
:::
:::

::: notes
To begin, here is an examplary outline of one of the studies conducted by myself. I considered four distinct population models, each differing in the presence of misspecifications, which was a key condition of interest. I also varied both sample size and indicator reliability. In each condition, four methods were compared: traditional SEM with ML, global SAM, local SAM with ML, and local SAM with unweighted least squares. As performance metrics, I assessed the bias of path estimates—indicating whether the model systematically over- or under-predicts by comparing the predicted and actual values—and the RMSE of path estimates, which measures the overall error magnitude and general accuracy of the estimates. Additionally, I calculated the coverage of the 95% confidence intervals for path estimates, representing the proportion of times the true path coefficient fell within the estimated interval.
:::

## Studies by Kosanke [based on @robitzsch_comparing_2022]{style="font-size: 20px;"}

![](figures/kosanke_studies_overview.png)

::: notes
Now, let's move on to an overview of Kosanke's studies. He conducted six simulation studies that replicated key aspects relevant to our research questions. He examined various population models to create different misspecification conditions, similar to my approach. However, he also included negative cross-loadings and residual correlations, placing a special emphasis on simple 2-factor CFA models. Furthermore, he varied the sample size, ranging from as small as 50 to as large as 100,000, as well as the reliability of the indicators. Although he used mostly the same methods and performance metrics as I did, there were some specific discrepancies between our approaches, which I will now explore in more detail.
:::

## Bias [ E.g.: Kriegmair Study 1: relative $\hat{\beta}$ bias values aggregated across parameters]{style="font-size: 20px;"}

::: r-fit-text
![](tables/aggregated_bias_study1.png)
:::

::: notes
Here, for example, are the aggregated relative bias values for the path estimates in my first study. I found that cross-loadings, in particular, led to a higher bias in SEM compared to SAM in conditions with small samples and low to moderate reliability.
:::

## Bias [ E.g.: Kosanke Study 1:]{style="font-size: 20px;"}

::: r-fit-text
```{r eval = TRUE, echo = FALSE}

# Load the relative bias results
bias_ci_s1 <- readRDS("../../LK/SimulationResultsProcessed/sim1_rel_bias_ci.rds")

shorten_names <- function(df) {
  df$method_metric <- sub("_rel_bias", "", df$method_metric)
  return(df)
}

# Function to create a styled table for each condition
create_styled_table <- function(data, condition) {
  data <- shorten_names(data)
  data <- data %>%
    mutate(across(where(is.numeric), ~ round(., 3)))
  
  # Format table
  kbl(data,
      col.names = c("Method", "50", "100", "250", "500", 
                    "1000", "2500", "100000"), booktabs = TRUE) %>%
    kable_styling(full_width = T, position = "left") %>%
    add_header_above(c(" " = 1, "Sample Size" = 7)) %>%
    column_spec(1, width = "3.5cm") %>% 
    row_spec(0, bold = TRUE) %>%
    kable_classic(full_width = F) %>%
    gsub("_", " ", .)
}
create_styled_table(bias_ci_s1[["2_-0.12"]], "2_-0.12")
```

[Relative bias of $\hat{\phi}$ in conditions with two negative unmodelled residual correlations in a 2-factor-CFA]{style="font-size: 22px;"}
:::

::: notes
Kosanke supported his claims with findings showing that SEM outperformed SAM in small to moderate samples in a 2-factor CFA model with unmodeled negative residual correlations. He argued that SAM performs worse than SEM under unmodeled negative cross-loadings and residual correlations due to LSAM’s negative small-sample bias. Ignoring positive residual correlations introduces a positive bias, which can cancel out, falsely making LSAM appear more accurate. Kosanke emphasized that this perceived robustness is misleading, as LSAM performs worse than SEM under certain conditions, particularly with unmodeled negative correlations.
:::


## Bias

::: r-fit-text
+---------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                                       | Kriegmair                                                                                                                                                                    | Kosanke                                                                                                                                                                                                                                                              |
+=======================================+==============================================================================================================================================================================+======================================================================================================================================================================================================================================================================+
| Verbal Dispute                        | "SEM performs worse than SAM in [low reliability]{style="color: green;"} x [low sample size]{style="color:blue;"} x [misspecification]{style="color:orange;"}"               | "SAM generally did not outperform traditional SEM in [small to moderate samples]{style="color:blue;"}." <br> <br> "\[under\] [unmodeled negative cross-loadings and residual correlations]{style="color:orange;"}, SAM tended to perform worse than traditional SEM" |
+---------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 4\. Experimental Design               | *N*:[100, 400]{style="color:blue;"}, 6400<br> [Reliability via $\Theta$ ]{style="color:green;"} <br> [Positive cross loadings & correlated residuals]{style="color:orange;"} | *N*:[50, 100, 250, 500]{style="color:blue;"}, 1000, 2500, 100000<br>[ Reliability via $\Lambda$]{style="color:green;"} <br> [Positive & negative cross loadings & correlated residuals (only in CFA)]{style="color:orange;"}                                         |
+---------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 5. Population Model                   | 5-factor-SEM                                                                                                                                                                 | 2-factor CFA & 5-factor SEM                                                                                                                                                                                                                                          |
+---------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 6. Analysis                           | Aggregated relative values and parameter-wise                                                                                                                                | Aggregated relative bias                                                                                                                                                                                                                                             |
+---------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
:::

::: notes
A closer examination allowed us to trace our differing claims back to specific choices made in our individual studies. \[▶︎\] Firstly, Kosanke included a "low" sample size of 50, while I started at 100. Secondly, I manipulated reliability by adjusting the indicator error variance, whereas Kosanke varied the factor loadings. Thirdly, I included only positive cross-loadings and correlated residuals, while Kosanke also included negative ones. Lastly, my results were based solely on a 5-factor SEM with a structural component, while Kosanke's findings were largely derived from estimating CFA models.
:::

## Collaboration
<div class="scrollable-table">
<table>
  <thead>
    <tr>
      <th></th>
      <th>Round 1</th>
      <th class="pastel-blue">Round 2</th>
      <th>Round 1</th>
    </tr>
  </thead>
  <tbody>
    <!-- Step 1 -->
    <tr>
      <td><strong>Steps</strong></td>
      <td>Kriegmair</td>
      <td class="pastel-blue">Joint Study</td>
      <td>Kosanke</td>
    </tr>
    <!-- Step 2 -->
    <tr>
      <td><strong>Population Model</strong></td>
      <td>
        5-factor-SEM
      </td>
      <td class="pastel-blue fragment" data-fragment-index="2">5-factor-SEM</td>
      <td>
        5-factor-SEM<br>
        <span class="strike fragment" data-fragment-index="2">2-factor-CFA</span>
      </td>
    </tr>
    <!-- Step 3 -->
    <tr class="grey-text">
      <td><strong>Data Generation</strong></td>
      <td>
        parametric & normally distributed
      </td>
      <td class="pastel-blue fragment" data-fragment-index="3">parametric & normally distributed</td>
      <td>
        parametric & normally distributed
      </td>
    </tr>
    <!-- Step 4 -->
    <tr>
      <td><strong>Experimental Design</strong></td>
      <td>
        <span class="strike fragment" data-fragment-index="4">Misspecifications (+)</span><br>
        *N*: 100 - <span class="strike fragment" data-fragment-index="4">6400</span><br>
        Reliability via Θ
      </td>
      <td class="pastel-blue fragment" data-fragment-index="4">
        Misspecifications (+/-)<br>
        *N*: 50, 100, 250, 400<br>
        Reliability via Θ
      </td>
      <td>
        Misspecifications (+/-)<br>
        *N*: 50 - <span class="strike fragment" data-fragment-index="4">100,000</span><br>
        <span class="strike fragment" data-fragment-index="4">Reliability via λ</span>
      </td>
    </tr>
    <!-- Step 5 -->
    <tr>
      <td><strong>Method Selection</strong></td>
      <td>
        <span class="strike fragment" data-fragment-index="5">SEM-ML</span>, gSAM, lSAM (ULS & ML)
      </td>
      <td class="pastel-blue fragment" data-fragment-index="5">
        constrained & unconstrained SEM, gSAM, lSAM (all ML)
      </td>
      <td>
        bounded SEM (<span class="strike fragment" data-fragment-index="5">ULS</span> & ML), gSAM, lSAM (ULS & ML)
      </td>
    </tr>
  </tbody>
</table>
</div>

<style>
  .scrollable-table {
    max-height: 65vh;
    overflow-y: auto;
    font-size: 0.6em;
  }
  .scrollable-table table {
    border-collapse: collapse;
    width: 100%;
  }
  .scrollable-table th, .scrollable-table td {
    border: 1px solid #ddd;
    padding: 4px;
    text-align: left;
  }
  .scrollable-table th {
    background-color: #f2f2f2;
    position: sticky;
    top: 0;
  }
  .strike {
    text-decoration: none;
  }
  .strike.visible {
    text-decoration: line-through;
  }
  .grey-text {
    color: grey;
  }
  .pastel-blue {
    background-color: #b3cde0;
  }
</style>

:::{.notes}
We then proceeded to align our decisions step-by-step in round 2. Due to time constraints, we limited the joint study's scope to a minimal level.

[▶︎] We agreed on using a 5-factor SEM population model since SAM is particularly designed for complex models with a structural part. [▶︎] We maintained the data generation and software as they were in our individual studies. [▶︎] We selected bounded ML SEM as the method of choice, as this had been suggested as a reason why SAM does not necessarily have a convergence rate advantage over SEM. [▶︎]
:::

## Collaboration
<div class="scrollable-table">
<table>
  <thead>
    <tr>
      <th></th>
      <th>Round 1</th>
      <th class="pastel-blue">Round 2</th>
      <th>Round 1</th>
    </tr>
  </thead>
  <tbody>
    <!-- Step 6 -->
    <tr>
      <td><strong>Estimands</strong></td>
      <td>
        β: Fixed at 0.1 <span class="strike fragment" data-fragment-index="6"> and varied</span>
      </td>
      <td class="pastel-blue fragment" data-fragment-index="6">
        β: Fixed at 0.1
      </td>
      <td>
        β: Fixed at 0.1<br>
        <span class="strike fragment" data-fragment-index="6">φ: Fixed and varied</span>
      </td>
    </tr>
    <!-- Step 7 -->
    <tr>
      <td><strong>Performance Metrics</strong></td>
      <td>
        Absolute bias in absolute values <br>
        <span class="strike fragment" data-fragment-index="7">Signed Relative bias</span><br>
        95% CI coverage<br>
        Convergence & Improper Solutions
      </td>
      <td class="pastel-blue fragment" data-fragment-index="7">
        Absolute bias in absolute and signed values<br>
        RMSE<br>
        95% CI coverage<br>
        Convergence & Improper Solutions
      </td>
      <td>
        Absolute bias in absolute values<br>
        <span class="strike fragment" data-fragment-index="7">Signed Relative bias</span><br>
        RMSE<br>
        95% CI coverage
      </td>
    </tr>
    <!-- Step 8 -->
    <tr class="grey-text">
      <td><strong>Software</strong></td>
      <td>
        lavaan::simulateData()
      </td>
      <td class="pastel-blue fragment" data-fragment-index="8">
        lavaan::simulateData()
      </td>
      <td>
        lavaan::simulateData()
      </td>
    </tr>
    <!-- Step 9 -->
    <tr>
      <td><strong>Analysis</strong></td>
      <td>
        Aggregated across parameters,<br> heat maps
      </td>
      <td class="pastel-blue fragment" data-fragment-index="9">
        Aggregated, <br> **parameter-wise**,<br>
        decision criteria <br> heat maps
      </td>
      <td>
        Aggregated across parameters,<br> decision criteria
      </td>
    </tr>
  </tbody>
</table>
</div>

<style>
  .scrollable-table {
    max-height: 65vh;
    overflow-y: auto;
    font-size: 0.6em;
  }
  .scrollable-table table {
    border-collapse: collapse;
    width: 100%;
  }
  .scrollable-table th, .scrollable-table td {
    border: 1px solid #ddd;
    padding: 4px;
    text-align: left;
  }
  .scrollable-table th {
    background-color: #f2f2f2;
    position: sticky;
    top: 0;
  }
  .strike {
    text-decoration: none;
  }
  .strike.visible {
    text-decoration: line-through;
  }
  .grey-text {
    color: grey;
  }
  .pastel-blue {
    background-color: #b3cde0;
  }
</style>

:::{.notes}
We limited the estimands to fixed coefficients, as no significant differences for the SAM vs. SEM comparison had been found in my initial studies. [▶︎] For performance metrics and analysis [▶︎], we included a parameter-wise analysis of bias to get a clearer picture of SAM's potential negative bias depending on the sign of cross-loadings and residual correlations.
:::

```{=html}
<style>
  .scrollable-table {
    max-height: 65vh;
    overflow-y: auto;
    font-size: 0.6em;
  }
  .scrollable-table table {
    border-collapse: collapse;
    width: 100%;
  }
  .scrollable-table th, .scrollable-table td {
    border: 1px solid #ddd;
    padding: 4px;
    text-align: left;
  }
  .scrollable-table th {
    background-color: #f2f2f2;
    position: sticky;
    top: 0;
  }
  .strike {
    text-decoration: none;
  }
  .strike.visible {
    text-decoration: line-through;
  }
  .grey-text {
    color: grey;
  }
  .pastel-blue {
    background-color: #b3cde0;
  }
</style>
```

::: notes
We limited the estimands to fixed coefficients, as no significant differences for the SAM vs. SEM comparison had been found in my initial studies. \[▶︎\] For performance metrics and analysis \[▶︎\], we included a parameter-wise analysis of bias to get a clearer picture of SAM's potential negative bias depending on the sign of cross-loadings and residual correlations.
:::

## Results of the Joint Study

## Bias - parameter-wise [ after collaboration ]{style="font-size: 20px;"}

![](tables/fig_bias_parameterwise_study3.png)

::: notes
We examined parameter-wise bias values under positive and negative cross-loadings and residual correlations. This was to test if SAM outperforms SEM even in the presence of negative misspecifications and to check whether the claim that a negative bias in SAM in small samples cancels out the positive bias from positive misspecifications holds true in a more complex model with a structural part.

Our analysis showed that switching the sign of the cross-loadings from positive to negative also led to more negative biases in SEM compared to SAM. This finding contradicts the claim that SAM outperforms SEM in the presence of negative misspecifications, and we do not observe a more negative bias in SAM with negative cross-loadings.

For correlated residuals, there was no clear relationship between bias direction and the sign of the correlation, with mostly negative biases across the board.
:::

## Bias: SEM - SAM [ after collaboration ]{style="font-size: 20px;"}

![](tables/fig_sam_sem_diff_study3.png){width=100%}

::: notes
Finally, I calculated the difference in bias between SEM and SAM to assess the relative performance of the two methods. The results show that SAM generally outperforms SEM in terms of bias, with the difference being more pronounced under positive cross-loadings and residual correlations. This suggests that SAM is more robust to misspecifications than SEM, even in the presence of negative biases.
:::

## 

Updating Verbal Claims <br> <br> SAM has no convergence rate advantage over bounded ML SEM <br> <br> SAM outperforms SEM despite of negative bias under positive and negative cross loadings in small samples and small to moderate reliability

::: notes
In conclusion, we can say that SAM does not have a convergence rate advantage over bounded ML SEM. However, it does outperform SEM despite a negative bias under both positive and negative cross-loadings in small samples and conditions of low to moderate reliability.
:::

## Evaluating the Adversarial Collaboration {auto-animate="true" auto-animate-easing="ease-in-out"}

::: columns
::: {.column width="25%"}
::: r-fit-text
<br> <br>

::: {.fragment fragment-index="2"}
[Diverging operationalizations:]{style="color: red;"} <br> [ - Method ]{style="color: red;"} <br> [ - Design ]{style="color: red;"} <br> [ - Reliability etc. ]{style="color: red;"}
:::

::: {.fragment fragment-index="3"}
</span> <span style="color: black;">→ Reduced ambiguity
:::

::: {.fragment fragment-index="4"}
→ Increased generalizability? </span>
:::

<br>

::: {.fragment fragment-index="2"}
[unified]{style="color: green;"}
:::
:::
:::

::: {.column width="50%"}
::: r-fit-text
```{dot}
digraph circular_process {
    // Use 'neato' layout for positioning
    layout=neato;
    overlap=false;
    splines=true;

    // Define global node attributes
    node [shape=plaintext, fontsize=12];

    // Define nodes with positions to form a circle
    hypothesize [label=< <font color="blue">Reformulated Verbal Claim</font> >, pos="0,1!"];
    operationalize [label=< <font color="green">Operationalizations</font> >, pos="-0.866,-0.5!", color="green"];
    gather_data [label=< <font color="green">Gather Data</font> >, pos="0.866,-0.5!", color="green"];

    // Define edges to create a circular process
    hypothesize -> operationalize [color="red"];
    operationalize -> gather_data [color="red"];
    gather_data -> hypothesize [color="red"];
}
```
:::
:::
:::

::: notes
Assessing our case study, we found that we were able to trace our disagreeing claims back to divergent design choices in our individual studies. Through collaboration, we jointly mapped our claims to a unified operationalization. This allowed us to develop a reformulated claim that integrates the differences between our individual studies, reducing ambiguity.

However, the question remains whether this process genuinely increased the generalizability of our claims to the wider range of applications in which researchers might actually use SAM or SEM.
:::

## Limitations and Future Directions

::: r-fit-text
::: fragment
-   "Toy" case study for AC<br> low stakes & no "real" adversaries <br> <br>
:::

::: fragment
-   Increased Generalizability? <br>
:::

::: fragment
still limited to specific (somewhat less) arbitrary choices for simulation<br>
:::

::: fragment
→ empirically ground simulations by sampling models (and data) from the literature (Taxonomy.jl)
:::

::: fragment
→ "living" simulations akin to open source software development
:::
:::

::: notes
This brings me to the limitations and future directions. Firstly, our case study was a "toy" example of adversarial collaboration. We were not true adversaries, and the stakes were relatively low, as we do not come from conflicting research backgrounds and have less experience in this field compared to more senior researchers.

Secondly, this process only partially increased generalizability, as we were still limited to specific, somewhat arbitrary choices for our individual and joint simulations.

One way to address this limitation would be to empirically ground simulations by sampling models and data from the literature. Our group is currently developing a Julia package called Taxonomy.jl to facilitate this.

Another approach would be to establish the practice of at least low-code adversarial simulation by all co-authors of a study. Although this would require more resources, it would allow for a more diverse set of designs and thus produce more generalizable results.
:::

## Personal Fit to the Project

### Meta Scientific Backgorund Experience
- Focused on enhancing generalizability in Monte Carlo simulations.
- Developed tools for sampling structural equation models as part of the **Taxonomy.jl project** at the Max Planck Institute.


## Personal Fit to the Project

### Skills
- **R**, **Python**, **Julia**
- Proficient in version control GitHub workflows and best practices for testdriven collaborative programming.
- Rapid learning capability of libraries and tools.
- Adversarial Simulation: Designed and realized collaborative computational research endavour.


## References