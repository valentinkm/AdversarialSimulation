---
Title: "Thesis"
author:
  - name: Valentin Kriegmair
    affiliations: "Humboldt-Universität zu Berlin"
fig-cap-location: top
format:
    pdf:
        fig-numbering: false
        fontsize: 11pt
        linestretch: 1.5
        geometry: "left=25mm, right=20mm, top=20mm, bottom=20mm"
        classoption: oneside
        papersize: a4
        header-includes: |
          \input{preamble.tex}
fontsize: 11pt
engine: knitr
bibliography: ../bibliography.bib
csl: ../apa.csl
appendix: true
---
```{r, include=FALSE}
library(knitr)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = FALSE)
```
```{r child = 'plots.qmd'}
```

```{=tex}
% \includepdf[pages=-]{cover.pdf}
```

\begin{center} \section*{Abstract} \end{center}
\noindent
{{< include abstract.qmd >}}

\vspace{1cm}

```{r, results = 'asis'}
latest_sha <- Sys.getenv("LATEST_SHA")
cat("#### Document Version: \n")
cat(paste0("Generated using [AdversarialSimulation](https://github.com/valentinkm/AdversarialSimulation) in state of Git commit SHA ", latest_sha))
```

\newpage

```{=tex}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
}
```

```{=tex}
\newpage
\tableofcontents
\newpage
```

```{=tex}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
}
```

# Introduction

## The Generalizability Challange

Karl Popper (1957) described science as the art of "systematic over-simplification." This phrase ironically yet accurately encapsulates the fundamental cycle of empirical research. Researchers formulate general hypotheses about the world, translate them into measurable constructs, select appropriate methods to collect data from specific populations, and finally update their beliefs about these general claims based on the gathered data. A core challenge in every research endeavor is mapping the general to the specific when designing and conducting a study and, conversely, mapping the specific empirical findings back to the general domain when interpreting results. This mapping process is central to research and is where many of a researcher's degrees of freedom lie. Divergences in these mappings can be the source of ambiguity and verbal disputes. When differences in these mappings are not recognized or lack transparency, persistent and seemingly unresolvable disagreements in the general domain can occur. 
This challenge extends to Monte Carlo simulation studies, which are commonly used to test statistical methods by evaluating them against known ground truths using simulated data. Since it is impossible to simulate and test every possible combination of data and analysis models, researchers face numerous degrees of freedom and decisions about which "prototypical" models to test in which "prototypical" data and settings. Comparing different methods regarding their general applicability and performance across various research settings is especially prone to conflicting claims based on divergent simulation decisions. Biases toward a specific method developed by a researcher may further amplify these divergences, not only during the interpretation of results but also during the design of simulations.

## Adversarial Collaboration

To address these challenges of entrenched disagreements, the practice of AC has been proposed to unveil discrepancies in underlying methodological decisions and assumptions. It was famously pioneered by Ralph Hertwig and Daniel Kahneman, who tried to settle a persistent scientific disagreement about frequency representation and consulted Barbara Mellers as a neutral arbiter. Today, it is recognized as a potent tool in the social empirical research community. The basic idea is for two researchers in disagreement to first identify a general verbal dispute and agree on a research question to settle the debate. Based on this, they collaboratively work on operationalizing, testing, and interpreting this verbal claim. This process aims to unveil and concretize underlying disagreements and thus reduce ambiguity and increase generalizability. In this project, we aimed to transfer the concept of AC from the empirical domain to Monte Carlo simulation studies and assess its feasibility and viability in a case study in this context. To conduct such an exemplary AC, we first need a framework that structures the collaborative process tailored to the outline of simulation studies. 

## SAM vs. SEM - a Case Study

Traditional SEM methods, like maximum likelihood estimation, optimize all parameters of a model simultaneously under the assumption of multivariate normality. While powerful and although robust estimation techniques relax the normality assumption, all system wide estimators suffer from several shortcomings, they often face issues such as non-convergence, improper solutions (with parameters out of definitional range), and biases from local measurement misspecifications that affect the entire model. They also typically require large sample sizes for adequate performance, especially in complex models.
 
To conduct an AC in the context of simulation studies...

# Methods

## A Framework for Adversarial Collaboration

We developed a specific adversarial simulation framework and structured the collaboration into two rounds. In the first round, each collaborator independently conducts a separate simulation study. In the second round, they come together to work on a joint study, building on the findings from the first round. This two-step approach is designed to highlight differences in a systematic way and to establish a virtual foundation for collaboration before engaging in a joint effort in our case study.

## Individual Simulation Studies

### Studies by Collaborator A (Kriegmair)

The methodological setup of my individual simulation studies follows the structure we established for our *adversarial simulation* framework to facilitate stepwise collaboration. It is based on a preregistered protocol but includes some deviations from the preregistration ([See Appendix A](#appendix-a) for the full protocol and all deviations from the preregistration). In the initial phase of our case study, I independently conducted two separate simulation studies without my collaborator's involvement with the goal to conceptually replicate the findings regarding SAM compared to standard SEM estimation of @rosseel_structural_2022 and @dhaene_evaluation_2023. However, there are several differences in the design and setup of the studies compared to the original studies as outlined below.

{{< include methods.qmd >}}

### Studies by Collaborator B (Kosanke)

{{< include methods_kosanke.qmd >}}

## Joint Simulation Study

{{< include methods_joint.qmd >}}

# Results

## Individual Simulation Studies

### Results of Collaborator A (Kriegmair)

{{< include results.qmd >}}

### Results of Collaborator B (Kosanke)

{{< include results_kosanke.qmd >}}

## Joint Simulation Study

{{< include results_joint.qmd >}}

# Discussion

The goal of this study was two-fold: First, to test the viability and practical applicability of adversarial collaboration (AC) as a tool to resolve disagreeing research claims and enhance generalizability and rigor in the context of simulation studies. Second, serving as a case study for this, to evaluate the performance of traditional Structural Equation Modeling (SEM) compared to Structural After Measurement (SAM) and resolve the conflicting claims of previous studies whether SAM consitently outperforms traditional SEM in the presence of model misspecifications in small to moderate sample sizes (@robitzsch_comparing_2022, @rosseel_structural_2022, @dhaene_evaluation_2023).

We successfully agreed on a joint starting point and translated conflicting verbal claims from prior studies into shared research questions. Based on these research questions, we independently conducted simulation studies largely based on the simulations by Rosseel (2022) and Dhaene and Rosseel (2023), successfully translating the verbal dispute back into the empirical domain.
It is important to note that this constituted only an emulated process of adversarial collaboration (AC), including an additional layer of abstraction through replication of previously published research findings. In a practical application of AC to simulation studies as proposed here, this intermediary step could be bypassed. Instead, collaborators could design two original studies or choose to work directly together on a unified research study, contingent upon their identification of a specific verbal disagreement.
Third, after assessing our individual studies and their results, we did not jointly conclude that conducting a collaborative unified simulation study as planned was warranted. Kosanke argued that while in most cases the Structural After Measurement (SAM) approach showed less bias and root mean square error (RMSE) in some settings—especially in cases of negative unmodeled residuals and cross-loadings—the advantages of traditional Structural Equation Modeling (SEM) countered those of SAM, indicating that neither method consistently outperformed the other in broader applications.
However, I identified several reasons for conducting another simulation based on this first round of replicated studies and, based on this, set up a *joint* study. Kosanke's conclusion about SAM's inconsistent outperformance of SEM only in the presence of negative misspecifications was applied to a very specific type of confirmatory factor analysis (CFA) model and was not tested in a more complex model with directed structural paths of interest. These represent scenarios for which @rosseel_structural_2022 proposed SAM to be advantageous.
In addition, to thoroughly investigate this assumed systematic underestimation of SAM, a parameter-wise analysis of bias was warranted. Aggregation of bias values across model parameters could lead to canceling out negative and positive values or not showing them at all when using absolute values. Furthermore, a joint study allowed for unifying simulation choices, such as extending the sample range to very small sizes (*N* = 50) to examine more extreme settings. Finally, collaborator-specific choices of tracking convergence rates and computing modulated indicator reliability levels could be identified as another potential source of diverging results, which was resolved in the joint study.

Idea: living simulations..

# References

::: {#refs}
:::

# Appendix {.appendix}

## Appendix A: Simulation Protocol {#appendix-a}

Here the full simulation protocol of my simulation studies conducted individually prior to collaboration as well as the follow up study I conducted in light of the collaboration with Kosanke after the first round of conducting and evaluating our individual studies is presented. It is based on the preregistration of my individual studies (@kriegmair_preregistration_2024) and outlines all deviations from it.

\addtocontents{toc}{\protect\setcounter{tocdepth}{0}}

{{< include appendix_a.qmd toc=false >}}

\addtocontents{toc}{\protect\setcounter{tocdepth}{2}}

## Appendix B: Supplementary Figures

```{=tex}
\renewcommand{\thefigure}{B\arabic{figure}}
\setcounter{figure}{0}
```
{{< include appendix_b.qmd toc=false >}}

## Appendix C: Detailed Error and Warning Messages

```{=tex}
\renewcommand{\thetable}{C\arabic{table}}
\setcounter{table}{0}
```
In the following, all different warning and error messages raised during the studies are listed (see Table C1) and shown how often they occurred under various fitting conditions (see Table C2).

{{< include appendix_c.qmd toc=false >}}