[
  {
    "objectID": "LIP_presentation.html#outline",
    "href": "LIP_presentation.html#outline",
    "title": "Adversarial Simulation",
    "section": "Outline",
    "text": "Outline\n\nThe Generalizability Challenge\nAdversarial Collaboration as Remedy\nAn Adversarial Simulation Framework   Time for questions  \nBackground: SAM vs. SEM\nFindings: Results and Collaboration\nOutlook: Evaluation and Future Directions   Discussion"
  },
  {
    "objectID": "LIP_presentation.html#the-generalizability-challenge",
    "href": "LIP_presentation.html#the-generalizability-challenge",
    "title": "Adversarial Simulation",
    "section": "1. The Generalizability Challenge",
    "text": "1. The Generalizability Challenge\n\n\n\n        \n\n\n\n\n\n\n\n\n\n\ncircular_process\n\n\n\nhypothesize\nHypothesize\n\n\n\noperationalize\nOperationalize\n\n\n\nhypothesize-&gt;operationalize\n\n\n\n\n\ngather_data\nGather Data\n\n\n\noperationalize-&gt;gather_data\n\n\n\n\n\ngather_data-&gt;hypothesize"
  },
  {
    "objectID": "LIP_presentation.html#the-generalizability-challenge-1",
    "href": "LIP_presentation.html#the-generalizability-challenge-1",
    "title": "Adversarial Simulation",
    "section": "The Generalizability Challenge",
    "text": "The Generalizability Challenge\n\n\n\n general & verbal    \n\nresearcher’s degrees of freedom \n\n\n→ ambiguity  → persistent disagreement\n\n   specific & empirical\n\n\n\n\n\n\n\n\n\n\ncircular_process\n\n\n\nhypothesize\n \nHypothesize\n \n\n\n\noperationalize\n \nOperationalize\n \n\n\n\nhypothesize-&gt;operationalize\n\n\n\n\n\ngather_data\n \nGather Data\n \n\n\n\noperationalize-&gt;gather_data\n\n\n\n\n\ngather_data-&gt;hypothesize\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScience is communicated through general verbal descriptions.\nEmpirical research, however, requires precise operationalization on the empirical plane.\nConflicts arise when verbal descriptions do not neatly map onto operationalized data.\nThis leads to persistent disagreements and ambiguity in scientific discourse."
  },
  {
    "objectID": "LIP_presentation.html#the-generalizability-challenge-2",
    "href": "LIP_presentation.html#the-generalizability-challenge-2",
    "title": "Adversarial Simulation",
    "section": "The Generalizability Challenge",
    "text": "The Generalizability Challenge\nIn Simulation Studies\n\n\n\n general & verbal     researchers degrees of freedom  → ambiguity \n\n→ persistant disagreement\n\n    specific & empirical\n\n\n\n\n\n\n\n\n\n\ncircular_process\n\n\n\nhypothesize\n \nMethod A vs. B\n \n\n\n\noperationalize\nModel,\n Estimands,\n Metrics etc.\n\n\n\nhypothesize-&gt;operationalize\n\n\n\n\n\ngather_data\n \nSimulate\n \n\n\n\noperationalize-&gt;gather_data\n\n\n\n\n\ngather_data-&gt;hypothesize"
  },
  {
    "objectID": "LIP_presentation.html#adversarial-collaboration-ac-as-a-remedy",
    "href": "LIP_presentation.html#adversarial-collaboration-ac-as-a-remedy",
    "title": "Adversarial Simulation",
    "section": "Adversarial Collaboration (AC) as a Remedy?",
    "text": "Adversarial Collaboration (AC) as a Remedy?\n\nPioneered by Mellers, Hertwig, and Kahneman (2001): \nRecognized in Empirical Research Melloni et al. (2023) Clark and Tetlock (2021)"
  },
  {
    "objectID": "LIP_presentation.html#adversarial-collaboration-ac",
    "href": "LIP_presentation.html#adversarial-collaboration-ac",
    "title": "Adversarial Simulation",
    "section": "Adversarial Collaboration (AC)",
    "text": "Adversarial Collaboration (AC)\n\n\n\n\n Identify general & verbal Disagreement \n\n\nAgree on:  - Operationalizations  - Test Design  - Interpretation\n\n\n → Reduce ambiguity→ Increase generalizability \n\n\n\nunify\n\n\n\n\n\n\n\n\n\n\n\ncircular_process\n\n\n\nhypothesize\n \nVerbal Dispute\n \n\n\n\noperationalize\n \nOperationalizations\n \n\n\n\nhypothesize-&gt;operationalize\n\n\n\n\n\ngather_data\n \nGather Data\n \n\n\n\noperationalize-&gt;gather_data\n\n\n\n\n\ngather_data-&gt;hypothesize\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScholars with opposing views jointly identify where their verbal descriptions and empirical evidence diverge.\nTranslate general verbal descriptions into mutually agreed operational definitions.\nThis mapping is key: aligning theoretical concepts with empirical measures.\nDevelop agreed-upon methods to test competing hypotheses, focusing on points of empirical disagreement.\nTests must capture both the nuances of verbal claims and the rigor of empirical standards.\nDevelop agreed-upon methods to test competing hypotheses, focusing on points of empirical disagreement.\nTests must capture both the nuances of verbal claims and the rigor of empirical standards.\nBoth sides collaborate in interpreting the findings, ensuring that conclusions respect the initial verbal intentions while reflecting empirical reality."
  },
  {
    "objectID": "LIP_presentation.html#creating-an-adversarial-simulation-framework",
    "href": "LIP_presentation.html#creating-an-adversarial-simulation-framework",
    "title": "Adversarial Simulation",
    "section": "Creating an Adversarial Simulation Framework",
    "text": "Creating an Adversarial Simulation Framework"
  },
  {
    "objectID": "LIP_presentation.html#structure-of-a-simulation-study",
    "href": "LIP_presentation.html#structure-of-a-simulation-study",
    "title": "Adversarial Simulation",
    "section": "Structure of a Simulation Study",
    "text": "Structure of a Simulation Study\n\n\n\n\n\n\n\n\nSteps of a Simulation Study\nContent\n\n\n\n\n1. Research Question\nVerbal description of Research Goals\n\n\n2. Population Model\nType, size, complexity\n\n\n3. Data Generation\nE.g. resampling vs. parametric draw\n\n\n4. Experimental Design\nSpecifiy conditions (e.g., sample size)\n\n\n5. Method Selection\nType, implementation, number\n\n\n6. Estimands\nPopulation level parameter values\n\n\n7. Performance Metrics\nE.g. Bias, Coverage etc.\n\n\n8. Software\nApplies to steps 2-7\n\n\n9. Analysis\nDecision criteria, graphical display etc.\n\n\n\n\n Siepe et al. (2023), Paxton et al. (2001), Morris, White, and Crowther (2019)\n\nVerbal description of research goals, Type, size, complexity, E.g. resampling vs. parametric draw, Specifiy conditions (e.g. sample size), Type, implementation, number, Population level parameter values, E.g. Bias, Coverage etc., Applies to steps 2-7, Decision criteria, graphical display etc."
  },
  {
    "objectID": "LIP_presentation.html#a-structured-adversarial-simulation-framework",
    "href": "LIP_presentation.html#a-structured-adversarial-simulation-framework",
    "title": "Adversarial Simulation",
    "section": "A Structured Adversarial Simulation Framework",
    "text": "A Structured Adversarial Simulation Framework\n\n\n\n\n\n\n\n\n\n\n\nRound 1\nRound 2\nRound 1\n\n\n\n\nSteps\nCollaborator 1\nJoint Study\nCollaborator 2\n\n\n1. Research Question\n\nAgreed upon prior to Round 1\n\n\n\n2. Population Model\n→\n\n←\n\n\n3. Data Generation\n→\n\n←\n\n\n4. Experimental Design\n→\n\n←\n\n\n5. Method Selection\n→\n\n←\n\n\n6. Estimands\n→\n\n←\n\n\n7. Performance Metrics\n→\n\n←\n\n\n8. Software\n→\n\n←\n\n\n9. Analysis\n→\n\n←"
  },
  {
    "objectID": "LIP_presentation.html#sam-vs-sem-background",
    "href": "LIP_presentation.html#sam-vs-sem-background",
    "title": "Adversarial Simulation",
    "section": "SAM vs SEM  Background",
    "text": "SAM vs SEM  Background"
  },
  {
    "objectID": "LIP_presentation.html#standard-sem-estimation-e.g.ml-adf-gls-uls",
    "href": "LIP_presentation.html#standard-sem-estimation-e.g.ml-adf-gls-uls",
    "title": "Adversarial Simulation",
    "section": "Standard SEM Estimation (e.g.ML, ADF, GLS, ULS)",
    "text": "Standard SEM Estimation (e.g.ML, ADF, GLS, ULS)\n\n\n\n\n\n\n\ne.g. normal theory-based maximum likelihood (ML) discrepancy function\nSystem-wide parameter (\\(\\vartheta\\)) optimization\nAssumes multivariate normal distribution\n\n\n\nProblems:\n\nnon-convergence issues\nimproper solutions\nbias due to local measurement misspecifications propagating to all model parameters\nrequiring large sample sizes for optimal statistical properties."
  },
  {
    "objectID": "LIP_presentation.html#structural-after-measurement-sam",
    "href": "LIP_presentation.html#structural-after-measurement-sam",
    "title": "Adversarial Simulation",
    "section": "Structural After Measurement (SAM)",
    "text": "Structural After Measurement (SAM)\n\n\n\n\n\nTwo-phase process:\n\n\\(\\vartheta_1\\): Measurement model  Local SAM (lSAM):  Separate “measurement blocks” Latent summary statistics and mapping matrix;  Global SAM (gSAM): Fixed measurement parameters for the entire measurement model.\n\n\n → \n\n\n\\(\\vartheta_2\\): Structural model\n\n\n\n\nRosseel and Loh (2022)\n\n\nLocal SAM (lSAM): Constructs the latent variable mean vector and variance-covariance matrix using observed data, measurement parameters, and a mapping matrix to inform the structural model estimation.\nGlobal SAM (gSAM): Directly estimates structural parameters using the full model while keeping measurement parameters fixed, without constructing latent variable summary statistics."
  },
  {
    "objectID": "LIP_presentation.html#sam-vs.-sem-disagreeing-reports",
    "href": "LIP_presentation.html#sam-vs.-sem-disagreeing-reports",
    "title": "Adversarial Simulation",
    "section": "SAM vs. SEM:  Disagreeing Reports",
    "text": "SAM vs. SEM:  Disagreeing Reports\n\n\n\n\n\n\n\n\nRosseel and Loh (2022), Dhaene and Rosseel (2023)\nRobitzsch (2022)\n\n\n\n\n- SAM outperformed SEM in terms of convergence, bias & RMSE in small samples x low item reliability, especially under misspecifications \n- SAM did not generally outperform traditional SEM in challenging conditions.  - SAM appears better: general negative small sample bias of SAM cancels out positive bias from positive misspecifications.\n\n\n\n \n\n\n→ Basis for a case study on adversarial collaboration"
  },
  {
    "objectID": "LIP_presentation.html#sam-vs.-sem-an-adversarial-simulation",
    "href": "LIP_presentation.html#sam-vs.-sem-an-adversarial-simulation",
    "title": "Adversarial Simulation",
    "section": "SAM vs. SEM:  an  Adversarial Simulation ",
    "text": "SAM vs. SEM:  an  Adversarial Simulation \n\n\n\n\n\n\n\n\nRosseel and Loh (2022), Dhaene and Rosseel (2023)\nRobitzsch (2022)\n\n\n\n\n- SAM outperformed SEM in terms of convergence, bias & RMSE in small samples x low item reliability, especially under misspecifications \n- SAM did not generally outperform traditional SEM in challenging conditions.  - SAM appears better: general negative small sample bias of SAM cancels out positive bias from positive misspecifications.\n\n\nReplication by Kriegmair\nReplication by Kosanke\n\n\n\n \n\n→ Basis for a case study on adversarial collaboration"
  },
  {
    "objectID": "LIP_presentation.html#research-questions-agreed-upon-prior-to-individual-studies",
    "href": "LIP_presentation.html#research-questions-agreed-upon-prior-to-individual-studies",
    "title": "Adversarial Simulation",
    "section": "Research Questions agreed upon prior to individual studies",
    "text": "Research Questions agreed upon prior to individual studies\n\nHow do SAM and traditional SEM methods (including ML and ULS) compare in terms of bias, Mean Squared Error (MSE), and convergence rates in small to moderate samples?\nWhat is the impact of model misspecifications, such as residual correlations and cross-loadings, on the performance of SAM compared to traditional SEM methods?"
  },
  {
    "objectID": "LIP_presentation.html#findings-of-the-case-study",
    "href": "LIP_presentation.html#findings-of-the-case-study",
    "title": "Adversarial Simulation",
    "section": "Findings of the Case Study",
    "text": "Findings of the Case Study\nReplication Results  Adversarial Collaboration"
  },
  {
    "objectID": "LIP_presentation.html#round-1-individual-studies",
    "href": "LIP_presentation.html#round-1-individual-studies",
    "title": "Adversarial Simulation",
    "section": "Round 1: Individual Studies",
    "text": "Round 1: Individual Studies\n\n\n\n\n\n\n\nKriegmair\nKosanke\n\n\n\n\nbased on Rosseel and Loh (2022) and Dhaene and Rosseel (2023)\nbased on Robitzsch (2022)"
  },
  {
    "objectID": "LIP_presentation.html#studies-by-kriegmair",
    "href": "LIP_presentation.html#studies-by-kriegmair",
    "title": "Adversarial Simulation",
    "section": "Studies by Kriegmair",
    "text": "Studies by Kriegmair"
  },
  {
    "objectID": "LIP_presentation.html#study-1-based-on-rosseel_structural_2022",
    "href": "LIP_presentation.html#study-1-based-on-rosseel_structural_2022",
    "title": "Adversarial Simulation",
    "section": "Study 1 based on Rosseel and Loh (2022)",
    "text": "Study 1 based on Rosseel and Loh (2022)\n\n\n\n\n\n\n\n\n\n1.1 no misspecifications \n\n\n1.2  cross loadings \n\n\n\n\n1.3  correlated residuals  \n\n\n1.4  structural misspecification  \n\n\n\n\n\n\nOther Conditions:\n\nN: 100, 400, 6400\nIndicator reliability: 0.3, 0.5, 0.7\n\nMethods:\n\nVanilla SEM with Maximum Likelihood (ML)\nGlobal SAM (gSAM)\nLocal SAM (lSAM-ML)\nLocal SAM with unweighted least squares (lSAM-ULS)\n\nPerformance Metrics:\n\nBias of path estimates\nRMSE of path estimates\nCoverage of 95% CI for path estimates"
  },
  {
    "objectID": "LIP_presentation.html#study-2-based-on-dhaene_evaluation_2023",
    "href": "LIP_presentation.html#study-2-based-on-dhaene_evaluation_2023",
    "title": "Adversarial Simulation",
    "section": "Study 2 based on Dhaene and Rosseel (2023)",
    "text": "Study 2 based on Dhaene and Rosseel (2023)\n\n\n\n\n\n\n\n2.1:\n\nNo measurement misspecifications\nEstimated paths absent in population\n\n\n\n\n\n2.2:\n\nEstimated paths absent in population\nIn exogenous analysis model\nIn endogenous analysis model \n\n\n\n\n\n\n\n\n\n\n\nOther Conditions:\n\nN: 100, 400, 6400\nIndicator reliability: 0.3, 0.5, 0.7\n\\(R^2\\): 0.1, 0.4\nMeasurement blocks: 3, 5\n\n\n\n\nMethods:\n\nVanilla SEM\nGlobal SAM\nLocal SAM\nLocal SAM with unweighted least squares"
  },
  {
    "objectID": "LIP_presentation.html#studies-by-kosanke-based-on-robitzsch_comparing_2022",
    "href": "LIP_presentation.html#studies-by-kosanke-based-on-robitzsch_comparing_2022",
    "title": "Adversarial Simulation",
    "section": "Studies by Kosanke based on Robitzsch (2022)",
    "text": "Studies by Kosanke based on Robitzsch (2022)"
  },
  {
    "objectID": "LIP_presentation.html#convergence-rate",
    "href": "LIP_presentation.html#convergence-rate",
    "title": "Adversarial Simulation",
    "section": "Convergence Rate",
    "text": "Convergence Rate\n\n\n\n\n\n\n\n\n\n\nKriegmair\nKosanke\n\n\n\n\nVerbal Dispute\nlow convergence rate of SEM\nno convergence issues\n\n\nMethod selection\nun-bounded ML SEM\nbounded ML SEM\n\n\nAnalysis\ncondition-wise rates\nglobal rate\n\n\n\ndirect:lavInspect(fit, \"converged\")\nindirect:quietly(safely(simulation_study_))"
  },
  {
    "objectID": "LIP_presentation.html#convergence-rate-e.g.-kriegmair-study-1",
    "href": "LIP_presentation.html#convergence-rate-e.g.-kriegmair-study-1",
    "title": "Adversarial Simulation",
    "section": "Convergence Rate  E.g.: Kriegmair Study 1:",
    "text": "Convergence Rate  E.g.: Kriegmair Study 1:"
  },
  {
    "objectID": "LIP_presentation.html#bias",
    "href": "LIP_presentation.html#bias",
    "title": "Adversarial Simulation",
    "section": "Bias",
    "text": "Bias\n\n\n\n\n\n\n\n\n\n\nKriegmair\nKosanke\n\n\n\n\nVerbal Dispute\n“SEM performes worse than SAM in low reliability x low sample size x misspecification”\n“SAM generally did not outperform traditional SEM in small to moderate samples.”   “[under] unmodelled negative cross-loadings and residual correlations, SAM tended to perform worse than traditional SEM”"
  },
  {
    "objectID": "LIP_presentation.html#bias-e.g.-kriegmair-study-1-absolute-hatbeta-bias-values-aggregated-across-parameters",
    "href": "LIP_presentation.html#bias-e.g.-kriegmair-study-1-absolute-hatbeta-bias-values-aggregated-across-parameters",
    "title": "Adversarial Simulation",
    "section": "Bias  E.g.: Kriegmair Study 1: absolute \\(\\hat{\\beta}\\) bias values aggregated across parameters",
    "text": "Bias  E.g.: Kriegmair Study 1: absolute \\(\\hat{\\beta}\\) bias values aggregated across parameters"
  },
  {
    "objectID": "LIP_presentation.html#bias-e.g.-kosanke-study-1",
    "href": "LIP_presentation.html#bias-e.g.-kosanke-study-1",
    "title": "Adversarial Simulation",
    "section": "Bias  E.g.: Kosanke Study 1:",
    "text": "Bias  E.g.: Kosanke Study 1:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Size\n\n\n\nMethod\n50\n100\n250\n500\n1000\n2500\n100000\n\n\n\n\nSEM ML\n-0.205\n-0.175\n-0.166\n-0.168\n-0.161\n-0.166\n-0.164\n\n\nSEM ULS\n-0.139\n-0.145\n-0.159\n-0.167\n-0.163\n-0.170\n-0.169\n\n\nLSAM ML\n-0.498\n-0.385\n-0.272\n-0.225\n-0.196\n-0.189\n-0.180\n\n\nLSAM ULS\n-0.497\n-0.385\n-0.272\n-0.225\n-0.196\n-0.189\n-0.180\n\n\nGSAM ML\n-0.497\n-0.385\n-0.272\n-0.225\n-0.196\n-0.189\n-0.180\n\n\nGSAM ULS\n-0.496\n-0.385\n-0.272\n-0.225\n-0.196\n-0.189\n-0.180\n\n\n\n\n\n\n\nRelative bias of \\(\\hat{\\phi}\\) in conditions with two negative unmodelled residual correlations in a 2-factor-CFA"
  },
  {
    "objectID": "LIP_presentation.html#bias-1",
    "href": "LIP_presentation.html#bias-1",
    "title": "Adversarial Simulation",
    "section": "Bias",
    "text": "Bias\n\n\n\n\n\n\n\n\n\n\nKriegmair\nKosanke\n\n\n\n\nVerbal Dispute\n“SEM performs worse than SAM in low reliability x low sample size x misspecification”\n“SAM generally did not outperform traditional SEM in small to moderate samples.”   “[under] unmodeled negative cross-loadings and residual correlations, SAM tended to perform worse than traditional SEM”\n\n\n4. Experimental Design\nN:100-6400  Reliability via Θ  Positive cross loadings & correlated residuals\nN:50-100000  Reliability via \\(\\lambda\\)  Positive & negative cross loadings and correlated residuals (only in CFA)\n\n\n \n \n \n\n\n \n \n \n\n\n\n\n\nIn Kosanke’s results, SAM appears to perform worse than traditional SEM under unmodeled negative cross-loadings and residual correlations. This happens because of bias cancellation in LSAM, particularly in small samples.\nLSAM tends to have a negative small-sample bias, and when you ignore positive residual correlations, that introduces a positive bias. These two biases can accidentally cancel each other out, making LSAM seem more accurate than it really is.\nHowever, this is a false perception of robustness, as LSAM performs inconsistently across different conditions, and in cases like unmodeled negative correlations, it actually does worse than SEM. Kosanke’s study shows that SAM doesn’t generally outperform traditional SEM in small to moderate samples, especially when negative biases are present."
  },
  {
    "objectID": "LIP_presentation.html#bias-2",
    "href": "LIP_presentation.html#bias-2",
    "title": "Adversarial Simulation",
    "section": "Bias",
    "text": "Bias\n\n\n\n\n\n\n\n\n\n\nKriegmair\nKosanke\n\n\n\n\nVerbal Dispute\n“SEM performs worse than SAM in low reliability x low sample size x misspecification”\n“SAM generally did not outperform traditional SEM in small to moderate samples.”   “[under] unmodeled negative cross-loadings and residual correlations, SAM tended to perform worse than traditional SEM”\n\n\n4. Experimental Design\nN:100, 400, 6400 Reliability via \\(\\Theta\\)   Positive cross loadings & correlated residuals\nN:50, 100, 250, 500, 1000, 2500, 100000 Reliability via \\(\\Lambda\\)  Positive & negative cross loadings & correlated residuals (only in CFA)\n\n\n 5. Population Model\n 5-factor-SEM\n 2-factor CFA & 5-factor SEM \n\n\n 6. Analysis\n Aggregated absolute values and parameter-wise \n Aggregated absolute values & aggregated relative bias"
  },
  {
    "objectID": "LIP_presentation.html#collaboration",
    "href": "LIP_presentation.html#collaboration",
    "title": "Adversarial Simulation",
    "section": "Collaboration",
    "text": "Collaboration\n\n\n\n\n\n\n\nRound 1\n\n\nRound 2\n\n\nRound 1\n\n\n\n\n\n\nSteps\n\n\nKriegmair\n\n\nJoint Study\n\n\nKosanke\n\n\n\n\n\nPopulation Model\n\n\n5-factor-SEM\n\n\n5-factor-SEM\n\n\n5-factor-SEM 2-factor-CFA\n\n\n\n\n\nData Generation\n\n\nparametric & normally distributed\n\n\nparametric & normally distributed\n\n\nparametric & normally distributed\n\n\n\n\n\nExperimental Design\n\n\nMisspecifications (+) N: 100 - 6400 Reliability via Θ\n\n\nMisspecifications (+/-) N: 50, 100, 250, 400 Reliability via Θ\n\n\nMisspecifications (+/-) N: 50 - 100,000 Reliability via λ\n\n\n\n\n\nMethod Selection\n\n\nSEM-ML, gSAM, lSAM (ULS & ML)\n\n\nbounded SEM-ML, gSAM, lSAM (ULS & ML)\n\n\nbounded SEM (ULS & ML), gSAM, lSAM (ULS & ML)\n\n\n\n\n\nEstimands\n\n\nβ: Fixed at 0.1  and varied\n\n\nβ: Fixed at 0.1\n\n\nβ: Fixed at 0.1 φ: Fixed and varied\n\n\n\n\n\nPerformance Metrics\n\n\nAbsolute bias in absolute values  RMSE 95% CI coverage Convergence & Improper Solutions\n\n\nAbsolute bias RMSE 95% CI coverage Convergence & Improper Solutions\n\n\nAbsolute bias in absolute values Relative bias RMSE 95% CI coverage\n\n\n\n\n\nSoftware\n\n\nlavaan::simulateData()\n\n\nlavaan::simulateData()\n\n\nlavaan::simulateData()\n\n\n\n\n\nAnalysis\n\n\nAggregated across parameters, heat maps\n\n\nAggregated,  parameter-wise, decision criteria  heat maps\n\n\nAggregated across parameters, decision criteria\n\n\n\n\n\n\n\n\nAdjusting the \\(\\Theta\\) matrix directly controls reliability by manipulating measurement error, aligning with its definition as the proportion of variance explained by the latent factor. Modulating \\(\\lambda\\) indirectly affects reliability but conflates factor strength with error variance, making it less precise in controlling reliability by definition."
  },
  {
    "objectID": "LIP_presentation.html#convergence-rate-after-collaboration-with-bounded-ml-sem",
    "href": "LIP_presentation.html#convergence-rate-after-collaboration-with-bounded-ml-sem",
    "title": "Adversarial Simulation",
    "section": "Convergence Rate  after collaboration (with bounded-ML SEM) ",
    "text": "Convergence Rate  after collaboration (with bounded-ML SEM)"
  },
  {
    "objectID": "LIP_presentation.html#bias---parameter-wise-after-collaboration",
    "href": "LIP_presentation.html#bias---parameter-wise-after-collaboration",
    "title": "Adversarial Simulation",
    "section": "Bias - parameter-wise  after collaboration ",
    "text": "Bias - parameter-wise  after collaboration"
  },
  {
    "objectID": "LIP_presentation.html#bias---aggregated-after-collaboration",
    "href": "LIP_presentation.html#bias---aggregated-after-collaboration",
    "title": "Adversarial Simulation",
    "section": "Bias - aggregated  after collaboration ",
    "text": "Bias - aggregated  after collaboration"
  },
  {
    "objectID": "LIP_presentation.html#section-2",
    "href": "LIP_presentation.html#section-2",
    "title": "Adversarial Simulation",
    "section": "",
    "text": "Updating Verbal Claims:   SAM has no convergence rate advantage over bounded ML SEM   SAM outperforms SEM despite of negative bias under positive and negative cross loadings in small samples and small to moderate reliability"
  },
  {
    "objectID": "LIP_presentation.html#evaluating-the-adversarial-collaboration",
    "href": "LIP_presentation.html#evaluating-the-adversarial-collaboration",
    "title": "Adversarial Simulation",
    "section": "Evaluating the Adversarial Collaboration",
    "text": "Evaluating the Adversarial Collaboration\n\n\n\n \n\nDiverging operationalizations:   - Method    - Design    - Reliability etc. \n\n\n → Reduced ambiguity\n\n\n→ Increased generalizability? \n\n\n\nunified\n\n\n\n\n\n\n\n\n\n\n\ncircular_process\n\n\n\nhypothesize\n \nReformulated Verbal Claim\n \n\n\n\noperationalize\n \nOperationalizations\n \n\n\n\nhypothesize-&gt;operationalize\n\n\n\n\n\ngather_data\n \nGather Data\n \n\n\n\noperationalize-&gt;gather_data\n\n\n\n\n\ngather_data-&gt;hypothesize\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSAM outperforms SEM despite of negative bias under cross loadings, small sample size and small to moderate reliability"
  },
  {
    "objectID": "LIP_presentation.html#limitations-and-future-directions",
    "href": "LIP_presentation.html#limitations-and-future-directions",
    "title": "Adversarial Simulation",
    "section": "Limitations and Future Directions",
    "text": "Limitations and Future Directions\n\n\n“Toy” case study for AC low stakes & no “real” adversaries  partly resolvable by thorough review  \n\n\n\n\nIncreased Generalizability? \n\n\n\nstill limited to specific (somewhat less) arbitrary choices for simulation\n\n\n→ empirically ground simulations by sampling models (and data) from the literature (Taxonomy.jl)"
  },
  {
    "objectID": "LIP_presentation.html#discussion",
    "href": "LIP_presentation.html#discussion",
    "title": "Adversarial Simulation",
    "section": "Discussion",
    "text": "Discussion\n\nIs the settling of verbal disputes through unified operationalizations really increasing generalizability?\nAre individual studies in prior to adversarial collaboration beneficial?\nHow could an incentive structure be designed to encourage adversarial collaboration?\nCould adversarial collaboration be implemented in the peer review process?"
  },
  {
    "objectID": "LIP_presentation.html#references",
    "href": "LIP_presentation.html#references",
    "title": "Adversarial Simulation",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nClark, Cory, and Philip Tetlock. 2021. “Adversarial Collaboration: The Next Science Reform.” In. https://doi.org/10.1007/978-3-031-29148-7_32.\n\n\nDhaene, Sara, and Yves Rosseel. 2023. “An Evaluation of Non-Iterative Estimators in the Structural After Measurement (SAM) Approach to Structural Equation Modeling (SEM).” Structural Equation Modeling: A Multidisciplinary Journal 30 (6): 926–40. https://doi.org/10.1080/10705511.2023.2220135.\n\n\nMellers, Barbara, Ralph Hertwig, and Daniel Kahneman. 2001. “Do Frequency Representations Eliminate Conjunction Effects? An Exercise in Adversarial Collaboration.” Psychological Science 12 (4): 269–75. https://doi.org/10.1111/1467-9280.00350.\n\n\nMelloni, Lucia, Liad Mudrik, Michael Pitts, Katarina Bendtz, Oscar Ferrante, Urszula Gorska, Rony Hirschhorn, et al. 2023. “An Adversarial Collaboration Protocol for Testing Contrasting Predictions of Global Neuronal Workspace and Integrated Information Theory.” PloS One 18 (2): e0268577. https://doi.org/10.1371/journal.pone.0268577.\n\n\nMorris, Tim P., Ian R. White, and Michael J. Crowther. 2019. “Using Simulation Studies to Evaluate Statistical Methods.” Statistics in Medicine 38 (11): 2074–2102. https://doi.org/10.1002/sim.8086.\n\n\nPaxton, Pamela, Patrick J. Curran, Kenneth A. Bollen, Jim Kirby, and Feinian Chen. 2001. “Monte Carlo Experiments: Design and Implementation.” Structural Equation Modeling: A Multidisciplinary Journal 8 (2): 287–312. https://doi.org/10.1207/S15328007SEM0802_7.\n\n\nRobitzsch, Alexander. 2022. “Comparing the Robustness of the Structural After Measurement (SAM) Approach to Structural Equation Modeling (SEM) Against Local Model Misspecifications with Alternative Estimation Approaches.” Stats 5 (3): 631–72. https://doi.org/10.3390/stats5030039.\n\n\nRosseel, Yves, and Wen Wei Loh. 2022. “A Structural After Measurement Approach to Structural Equation Modeling.” Psychological Methods, No Pagination Specified–. https://doi.org/10.1037/met0000503.\n\n\nSiepe, Björn S., František Bartoš, Tim P Morris, Anne-Laure Boulesteix, Daniel W. Heck, and Samuel Pawel. 2023. “Simulation Studies for Methodological Research in Psychology: A Standardized Template for Planning, Preregistration, and Reporting.” Preprint. PsyArXiv. https://doi.org/10.31234/osf.io/ufgy6."
  }
]