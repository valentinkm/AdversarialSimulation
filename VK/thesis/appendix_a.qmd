```{r, include=FALSE}
library(lavaan)
library(Matrix)
source("../simulation/gen_mat.R")

# Matrices of study 1:
MLIST_1_1 <- gen_mat("1.1")
MLIST_1_2 <- gen_mat("1.2")
MLIST_1_3 <- gen_mat("1.3")
MLIST_1_4 <- gen_mat("1.4")

# Matrices of study 2:
MLIST_2_1 <- gen_mat("2.1")

# Matrices of study 3:
MLIST_3_1 <- gen_mat("3.1_negative")
MLIST_3_2 <- gen_mat("3.2_negative")

matrix_to_latex <- function(mat, decimals = 1) {
  nrow <- nrow(mat)
  ncol <- ncol(mat)
  latex_code <- "\\begin{bmatrix}\n"
  for (i in 1:nrow) {
    row_values <- sapply(mat[i, ], function(x) {
      if (x == 0) {
        "0"
      } else {
        formatC(x, format = "f", digits = decimals)
      }
    })
    latex_code <- paste0(latex_code, paste(row_values, collapse = " & "))
    if (i < nrow) {
      latex_code <- paste0(latex_code, " \\\\\n")
    } else {
      latex_code <- paste0(latex_code, "\n")
    }
  }
  latex_code <- paste0(latex_code, "\\end{bmatrix}")
  return(latex_code)
}

# latex matrices for stuyd 1:
beta_latex_1_1 <- matrix_to_latex(MLIST_1_1$beta)
beta_latex_1_2 <- matrix_to_latex(MLIST_1_2$beta)
beta_latex_1_3 <- matrix_to_latex(MLIST_1_3$beta)
beta_latex_1_4 <- matrix_to_latex(MLIST_1_4$beta)
psi_latex_1 <- matrix_to_latex(MLIST_1_1$psi)
lambda_latex_1 <- matrix_to_latex(MLIST_1_1$lambda)
lambda_latex_1_3 <- matrix_to_latex(MLIST_1_2$lambda)

# latex matrices for study 3:
beta_latex_3_1 <- matrix_to_latex(MLIST_3_1$beta)
psi_latex_3_1 <- matrix_to_latex(MLIST_3_1$psi)

# latex matrices for study 2: 
beta_latex_2_1 <- matrix_to_latex(MLIST_2_1$beta)
```

**Preregistration template designed by:** Björn S. Siepe, František Bartoš, Tim P. Morris, Anne-Laure Boulesteix, Daniel W. Heck, and Samuel Pawel

## 1. General Information

### 1.1 What is the title of the project?

Comparing a Structural After Measurement (SAM) Approach to Standard Structural Equation Model (SEM) Estimation

### 1.2 Who are the current and future project contributors?

Valentin Kriegmair

### 1.3 Provide a description of the project.

The studies registered were part of an adversarial collaboration project. The aim was to conceptually (only in part) replicate the results obtained by @dhaene_evaluation_2023 and @rosseel_structural_2022. I set out to evaluate the performance of a Structural After Measurement (SAM) approach for estimating structural equation models (SEM) in comparison to standard SEM estimation methods. This served as the basis for the adversarial collaboration with another researcher who evaluated the same research question from the perspective of a conceptual replication of the (in part contradicting) results obtained by @robitzsch_comparing_2022. However, the following only describes the first (conceptual) replication.

### 1.4 Did any of the contributors already conduct related simulation studies on this specific question?

No prior related simulation studies have been conducted by the contributors.

## 2. Aims

Structural After Measurement (SAM) is an estimation method for structural equation models that consists of a stepwise estimation of the measurement and structural parts of a model. The research questions of the current simulation were:

1. How do SAM and traditional SEM methods (including ML and ULS) compare in terms of bias, Mean Squared Error (MSE), and convergence rates in small to moderate samples?

2. What is the impact of model misspecifications, such as residual correlations and cross-loadings, on the performance of SAM compared to traditional SEM methods?

## 3. Data-Generating Mechanism

### 3.1 Study 1

In study 1 (conceptually replicating @rosseel_structural_2022) data was generated parametrically. Four different population structural equation models (SEM) with five latent variables and three continuous indicators per facotr based on the following matrices were simulated:

- $\boldsymbol{B}$ as $M \times M$ matrix representing latent regression coefficients with all $b = 0.1$.
    ```{r, results='asis', echo=FALSE}
    cat("
    - Model 1.1 and 1.2:
    $$\\boldsymbol{B} = ", beta_latex_1_1, "$$
    - Model 1.3 in deviation from the preregistration with a reversed effect between latent factors f3 and f4 to introduce another realistic and more severe misspecification to show the potential of SAM in most challenging conditions:
    $$\\boldsymbol{B} = ", beta_latex_1_3, "$$
    - Model 1.4 in deviation from the preregistration with a bidirectional structural relation between f3 and f4 specified as only one directional instead of just reversing the effect to investigate a different type of misspecification:
    $$\\boldsymbol{B} = ", beta_latex_1_4, "$$")
    ```

- $\boldsymbol{\Psi}$ as $M \times M$ as diagonal matrix representing the residual variances in deviation from the preregistration not adjusted for the varying structural relations. This was only updated in the joint study (study 3) to adjust residual variances of all endogenous factors to accurately reflect the number of regressors
    ```{r, results='asis', echo=FALSE}
    cat(" - Model 1.1, 1.2, 1.3, and 1.4:
    $$\\boldsymbol{\\Psi} = ", psi_latex_1, "$$")
    ```

- $\boldsymbol{\Lambda}$ as $P \times M$ matrix representing factor loadings.
    ```{r, results='asis', echo=FALSE}
    cat(" - Model 1.1, 1.3 and 1.4:
    $$\\boldsymbol{\\Lambda} = ", lambda_latex_1, "$$")
    ```

    - Model 1.2: cross loadings will be set to be 10% lower than the factor loadings: $\Lambda_{ik,jk} = 0.63 = 0.9 \times 0.7$. They will be generated by the following elements in $\Lambda$: (2, 2), (5, 3), (8, 4), (11, 5), (14, 1).

- $\boldsymbol\Theta$ as a $P \times P$ matrix representing the residual variances and covariances of the indicators.

    - Model 1.1, 1.2 and 1.4: The diagonal generated as: $$\Theta^* = \mathbf{\Lambda} \operatorname{Var}(\boldsymbol{\eta}) \boldsymbol{\Lambda}^T \times \frac{1}{r-1}$$
        (where $r$ is the reliability of the indicators) and 0 on all off-diagonal elements
    - Model 1.3:
        - $\Theta^*$ on the diagonal.
        - Correlated residuals generated between specific indicator pairs: for $i = (2, 5, 8, 11, 14)$ and $i' = (3, 6, 9, 12, 15)$, and for each $k=1,\ldots,4$ and $l=k+1,\ldots,5$, the entries $(i_k, i'_l)$ and $(i'_l, i_k)$ in $\Theta$ are set to $0.6 \times \min \Theta^*$, ensuring correlated errors among selected indicator pairs without exceeding a 0.6 correlation coefficient.

### 3.1.2 Study 2

For study 2, again, different five-factor population models with three continious indicators per facotr were generated parametrically . Further, the different models of study 2 were used for different simulation settings resulting in two sub-studies 2.1 and 2.2 (see simulation settings).

- $\boldsymbol{B}$ as $M \times M$ matrix representing latent regression coefficients with varying parameter size defined by two conditions of endogenous factor variance explained by the exogenous factors (low: $R^2 = 0.1$ or medium: $R^2 = 0.4$ see below under factor):

    - Model 2.1 and 2.2: $$
          \boldsymbol{B} = \begin{bmatrix} 
          0 & 0 & 0 & 0 & 0 \\
          0 & 0 & 0 & 0 & 0 \\
          0 & 0 & 0 & 0 & 0 \\
          \beta_{\eta_4,\eta_1} & \beta_{\eta_4,\eta_2} & 0 & 0 & 0 \\
          0 & \beta_{\eta_5,\eta_2} & \beta_{\eta_5,\eta_3} & \beta_{\eta_5,\eta_4} & 0 \\
          \end{bmatrix}
          $$

- $\boldsymbol\Lambda$ as $P \times M$ matrix representing factor loadings of indicators on the latent factors.

    - Model 2.1: $$
          \boldsymbol\Lambda = \begin{bmatrix}
          1 & 0 & 0 & 0 & 0 \\
          0.9 & 0 & 0 & 0 & 0 \\
          0.8 & 0 & 0 & 0 & 0 \\
          0 & 1 & 0 & 0 & 0 \\
          0 & 0.9 & 0 & 0 & 0 \\
          0 & 0.8 & 0 & 0 & 0 \\
          0 & 0 & 1 & 0 & 0 \\
          0 & 0 & 0.9 & 0 & 0 \\
          0 & 0 & 0.8 & 0 & 0 \\
          0 & 0 & 0 & 1 & 0 \\
          0 & 0 & 0 & 0.9 & 0 \\
          0 & 0 & 0 & 0.8 & 0 \\
          0 & 0 & 0 & 0 & 1 \\
          0 & 0 & 0 & 0 & 0.9 \\
          0 & 0 & 0 & 0 & 0.8 \\
          \end{bmatrix}
          $$

    - Model 2.2 with cross-loadings either in the exogenous ($\lambda_{6,3}$), endogenous ($\lambda_{12,5}$) or both parts of the model. Which cross loading was present depended on the misspecification simulation factor. The specific magnitude of the endogenous ($\lambda_{12,5}$) loading depended on $R^2$ (see under 3.2.2): $$
          \boldsymbol\Lambda = \begin{bmatrix}
          1 & 0 & 0 & 0 & 0 \\
          0.9 & 0 & 0 & 0 & 0 \\
          0.8 & 0 & 0 & 0 & 0 \\
          0 & 1 & 0 & 0 & 0 \\
          0 & 0.9 & 0 & 0 & 0 \\
          0 & 0.8 & \lambda_{6,3} & 0 & 0 \\
          0 & 0 & 1 & 0 & 0 \\
          0 & 0 & 0.9 & 0 & 0 \\
          0 & 0 & 0.8 & 0 & 0 \\
          0 & 0 & 0 & 1 & 0 \\
          0 & 0 & 0 & 0.9 & 0 \\
          0 & 0 & 0 & 0.8 & \lambda_{12,5} \\
          0 & 0 & 0 & 0 & 1 \\
          0 & 0 & 0 & 0 & 0.9 \\
          0 & 0 & 0 & 0 & 0.8 \\
          \end{bmatrix}
          $$

- $\boldsymbol\Theta$ as a $P \times P$ matrix representing the residual variances and covariances of the indicators. This was computed as the portion of the indicator's total variance that is not explained by the latent factors, after accounting for the strength and reliability of its relationship to these factors (factor loadings), as well as the effects of regressions between the latent factors themselves.

    - Model 2.1: The diagonal of $\boldsymbol\Theta$ generated as: $$\Theta^* = \mathbf{\Lambda} \operatorname{Var}(\boldsymbol{\eta}) \boldsymbol{\Lambda}^T \times \frac{1}{r-1}$$
        (where $r$ is the reliability of the indicators) and 0 on all off-diagonal elements
    - Model 2.2:
        - $\Theta^*$ on the diagonal.
        - Correlated residuals generated between specific indicator pairs in either the endogenous, exogenous or both parts of the model.

        Thus depending on the simulation setting either:

        - $\Theta_{8,9}$, $\Theta_{9,8}$ (exogenous part)
        - $\Theta_{14,15}$ and $\Theta_{15,14}$ (endogenous part)
        - $\Theta_{8,9}$, $\Theta_{9,8}$, $\Theta_{14,15}$ and $\Theta_{15,14}$ (both parts)

        were set $0.6 \times \min \Theta^*$, ensuring correlated errors among selected indicator pairs without exceeding a 0.6 correlation coefficient:

### 3.1.3 Study 3

For study 3, again, four different five-factor population models with three indicators per factor were generated parametrically with $\boldsymbol{B}$ as $M \times M$ matrix representing latent regression coefficients with all $b = 0.1$ for all models in study 3:

```{r, results='asis', echo=FALSE}
cat("$$\\boldsymbol{\\Psi} = ", beta_latex_3_1, "$$")
```

and $\boldsymbol{\Psi}$ as $M \times M$ as diagonal matrix (0 on the off diagonal) representing variances of the factors with $1-kb^2$ on the diagonal where $k$ is the number of latent regressor per factor and $b$ the regression coefficients (0.1) for all models in study 3. Each model in study 3 included either cross loadings or correlated residual errors in the measurement model based on $\boldsymbol\Lambda$ and $\boldsymbol\Theta$ (constructed as in study 1) but these modifications in the measurement models could be either positive or negative.

### 3.2 Factors of the Data-Generating Mechanism

#### 3.2.1 Study 1

The first study modulated the following factors:

- Different misspecifications of the population model where the population model varies between the different models (1.1, 1.2, 1.3, 1.4) as described above, while the analysis model remains specified as model 1.1.
- Sample sizes of small (N = 100), medium (N = 400), or large (N = 6400)
- Indicator reliability of low (.3), moderate (.5), or high (.7)

#### 3.2.2 Study 2

The second study modulated the following factors of the data generating process across both studies:

- Sample sizes of small (N = 100), medium (N = 400), or large (N = 6400)
- Variance explained ($R^2$) of the endogenous factor variance explained by the exogenous factors: low ($R^2 = 0.1$) or medium ($R^2 = 0.4$)
- Indicator reliability of three indicators per factor: *all high* (.8), *all low* (.5), *average low* (.5) varying between .7 to .3 with the highest reliability for the scaling indicator.
- Sample sizes of small (N = 100), medium (N = 400), or large (N = 6400)
- Deviating from the preregistration distribution (normal vs. non-normal) was not considered in the simulation settings to limit the scope of the study.
- Measurement misspecifications of a residual covariance and a factor loading either in the exogenous, endogoneous or both parts of the model (in deviation from the preregistration without additional structural misspecifications and only three modulations to limit the scope of the study):
- Number of measurement blocks (how many separate measurement models are fitted in the first step of SAM) of either a separate measurement model per latent variable (b = k = 5) or one joint measurement model for all exogenous variables (b = 3)

In deviation from the preregistration, additionally all models in study 2 were estimated including stuructral specifications that were not present in the population model to investigate the performance of the methods on recovering falsely specified absent structural relations.

#### 3.2.3 Study 3

The third study modulated the following factors of the data generating process:

- Sample sizes of N = 50, N = 100, N = 250 and N = 400.
- Indicator reliability of low (.3), moderate (.5), or high (.7)

### 3.3 Simulation Conditions

-  Study 1: in deviation from the preregistration only one estimattion model was considered to limit the scope of the study resulting in 36 conditions (4 population models x 3 sample sizes x 3 reliabilities) 
- Study 2.1 (4 population models x 3 sample sizes x 2 $R^2$ x 3 reliabilities x 2 measurement blocks = 144 conditions)
    (in dviation from the preregistration the misspecifications were reduced and counted here as differnet population odels as well)

## 4. Estimands and Targets

Estimated structural model parameters (path coefficients) represented the estimands of interest. 

## 5. Methods

Both studies will compare four different estimation methods for SEMs:

- Traditional SEM: (structural and measurement model estimated simultaneously) (rationale: the current standard approach in SEM estimation serving as a baseline with maximum likelihood (ML)):
- SAM: (separating the estimation of the measurement and structural model to alleviate the potential for propagation of bias from (e.g. misspecified) measurement part to the structural part of the model)
    - Local SAM (Uses summary statistics from the measurement model to derive the model-implied mean vector and variance-covariance matrix of latent variables. These statistics are then utilized to estimate the structural parameters. A mapping matrix (M) is used to transform the observed data into the latent variable space. It can be estimated using different methods.)
        - With ML mapping matrix (Akin to a factor score approach (@bartlett_statistical_1937, @bartlett_methods_1938))
        - With ULS mapping matrix (Uses the Moore-Penrose pseudoinverse, suitable for scenarios with complex or underdetermined systems, where the K matrix is rank-deficient but requires adjustments for structural constraints.)
    - Global SAM (rationale: Fixing the parameters obtained from the measurement model in the first step, and then using them as constants in the full SEM during the second step. Suitable for models where local SAM is impractical due to higher-order latent variables or rank deficiencies in $\lambda$.)

Traditional SEM as well as both steps in the SAM approach will be estimated using Maximum Likelihood (ML) using the `lavaan` (@rosseel_lavaan_2012) package in R (@r_core_team_r_2023).

## 6. Performance Measures

Across both studies the following performance measures were captured:

- Convergence rates: Proportions of observed data sets that successfully converged for each estimation method detected using `lavaan`.
- In deviation from the preregistration also impropper solutions of converged models showing negative variances as the only type of improper solution present were computed.
- Rrelative biases: Average difference between an estimate and its true value, normalized by the true value, assessed across all path coefficients: $\frac{\bar{T} - \theta}{\theta}$
- Absolute biases: (in deviation from the preregistration this measure as it might be more intuitive and applicable for study 1 and 3 with invariant regression weights): ($\bar{T} - \theta$)
- Root Mean Squared Errors (RMSE): Calculated as the square root of the average squared difference between an estimate and its true value, evaluated under conditions of model misspecification: ($\sqrt{\frac{1}{K} \sum_{k=1}^{K} (T_k - \theta)^2}$) where $T_k$ is the estimated parameter, $\bar{T}$ the mean of the estimated parameters and $\theta$ the true parameter value, and $K$ is the number of replications computed.
- Relative Root Mean Squared Errors (RRMSE) in deviation from preregistration for better comparability in study 2 under varying regression weights:$\sqrt{\frac{(\bar{T} - \theta)^2 + S_T^2}{\theta^2}}$
- Empirical coverage levels of 95% confidence intervals (CIs): Proportion of observed data sets where the constructed CIs included the true value. (Not reported to limit the scope)

## 7. Monte Carlo Uncertainty of the Estimated Performance Measures

Monte Carlo uncertainty was calculated (manually in deviation from the preregistration) for the absolute and relative metrics: $\sqrt{\frac{S_T^2}{K}}$ and $\sqrt{\frac{S_T^2}{K\theta^2}}$ for bias and relative bias, and $\sqrt{\frac{K-1}{K} \sum_{j=1}^{K} \left( \text{RMSE}_{(j)} - \text{RMSE} \right)^2}$ and $\sqrt{\frac{K-1}{K} \sum_{j=1}^{K} \left( rRMSE_{(j)} - rRMSE \right)^2}$ for RMSE and relative RMSE.

## 8. Simulation Repetitions

- Replicating @rosseel_structural_2022 study 1 consisted of 5000 repetitions per condition.
- Replicating @dhaene_evaluation_2023 study 2 will consisted of 10000 repetitions per condition.
- Study 3 entailed 5000 repitiions as this resulted in sufficiently small Monte Carlo standard errors for the performance measures.

## 9. Missing Values due to non-convergence or other reasons

As mentioned above convergence rates were captured and only converged propper solutions were used for performance measure computation.

## 10. Software and Libraries

The simulation was set up and conducted in @r_core_team_r_2023 using the `lavaan` package for generating data based on the population models as well as for applying SEM estimation methods (@rosseel_lavaan_2012) as well as the `furrr` (@davis_furrr_2022) package for parallel simulation execution. A full list of libraries and dependencies can be found on [GitHub](https://github.com/valentinkm/AdversarialSimulation/blob/main/VK/simulation/renv.lock)

## 11. Computational Environment

The simulations were conducted using the TARDIS high-performance computing cluster at the Max Planck Institute for Human Development. The computational environment was set up in R, utilizing a suite of packages for analysis and parallel computing. Key libraries included:

- Analysis and Data Manipulation Packages: `MASS`, `dplyr`, `tidyr`, `lavaan`, `purrr`, and `Matrix`.
- Parallel Computing Packages: `future`, `furrr`, `parallel`, `future` and `batchtools`.


## 12. Reproducibility

The code of the simulation was made available on [GitHub] (https://github.com/valentinkm/AdversarialSimulation). A pre-generated list of seeds was used for all replications to ensure reproducibility and avoid synchronization in parallelized computations. As a examplary replication the simulation can be reproduced in this GitHub action [here]().