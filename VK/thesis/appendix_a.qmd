---
bibliography: ../bibliography.bib
format: pdf
---
```{r, include=FALSE}
library(lavaan)
library(Matrix)
source("../simulation/gen_mat.R")

# Matrices of study 1:
MLIST_1_1 <- gen_mat("1.1")
MLIST_1_2 <- gen_mat("1.2")
MLIST_1_3 <- gen_mat("1.3")
MLIST_1_4 <- gen_mat("1.4")

# Matrices of study 3:
MLIST_3_1 <- gen_mat("3.1_negative")
MLIST_3_2 <- gen_mat("3.2_negative")

matrix_to_latex <- function(mat, decimals = 1) {
  nrow <- nrow(mat)
  ncol <- ncol(mat)
  latex_code <- "\\begin{bmatrix}\n"
  for (i in 1:nrow) {
    row_values <- sapply(mat[i, ], function(x) {
      if (x == 0) {
        "0"
      } else {
        formatC(x, format = "f", digits = decimals)
      }
    })
    latex_code <- paste0(latex_code, paste(row_values, collapse = " & "))
    if (i < nrow) {
      latex_code <- paste0(latex_code, " \\\\\n")
    } else {
      latex_code <- paste0(latex_code, "\n")
    }
  }
  latex_code <- paste0(latex_code, "\\end{bmatrix}")
  return(latex_code)
}

# latex matrices for stuyd 1:
beta_latex_1_1 <- matrix_to_latex(MLIST_1_1$beta)
beta_latex_1_2 <- matrix_to_latex(MLIST_1_2$beta)
beta_latex_1_3 <- matrix_to_latex(MLIST_1_3$beta)
beta_latex_1_4 <- matrix_to_latex(MLIST_1_4$beta)
psi_latex_1 <- matrix_to_latex(MLIST_1_1$psi)
lambda_latex_1 <- matrix_to_latex(MLIST_1_1$lambda)
lambda_latex_1_3 <- matrix_to_latex(MLIST_1_2$lambda)

# latex matrices for study 3:
beta_latex_3_1 <- matrix_to_latex(MLIST_3_1$beta)
psi_latex_3_1 <- matrix_to_latex(MLIST_3_1$psi)
```

**Preregistration template designed by:** Björn S. Siepe, František Bartoš, Tim P. Morris, Anne-Laure Boulesteix, Daniel W. Heck, and Samuel Pawel

## 1. General Information

### 1.1. What is the title of the project?

Comparing a Structural After Measurement (SAM) Approach to Standard Structural Equation Model (SEM) Estimation

### 1.2. Who are the current and future project contributors?

Valentin Kriegmair

### 1.3. Provide a description of the project.

The studies registered were part of an adversarial collaboration project. The aim was to conceptually (only in part) replicate the results obtained by @dhaene_evaluation_2023 and @rosseel_structural_2022. I set out to evaluate the performance of a Structural After Measurement (SAM) approach for estimating structural equation models (SEM) in comparison to standard SEM estimation methods. This served as the basis for the adversarial collaboration with another researcher who evaluated the same research question from the perspective of a conceptual replication of the (in part contradicting) results obtained by @robitzsch_comparing_2022. However, the following only describes the first (conceptual) replication.

### 1.4. Did any of the contributors already conduct related simulation studies on this specific question?

No prior related simulation studies have been conducted by the contributors.

## 2. Aims

Structural After Measurement (SAM) is an estimation method for structural equation models that consists of a stepwise estimation of the measurement and structural parts of a model. The research questions of the current simulation were:

1.  How do SAM and traditional SEM methods (including ML and ULS) compare in terms of bias, Mean Squared Error (MSE), and convergence rates in small to moderate samples?

2.  What is the impact of model misspecifications, such as residual correlations and cross-loadings, on the performance of SAM compared to traditional SEM methods?

## 3. Data-Generating Mechanism

### 3.1. How will the parameters for the data-generating mechanism (DGM) be specified?

#### 3.1.1 Study 1

In study 1 (conceptually replicating @rosseel_structural_2022) data was generated parametrically. Four different population structural equation models (SEM) with latent variables and continuous indicators based on the following matrices were simulated:

- $\boldsymbol{B}$ as $M \times M$ matrix representing latent regression coefficients with all $b = 0.1$.
    ```{r, results='asis', echo=FALSE}
    cat("
    - **Model 1.1 and 1.2:**
    $$\\boldsymbol{B} = ", beta_latex_1_1, "$$
    - **Model 1.3** in deviation from the preregistration with a reversed effect between latent factors f3 and f4 to introduce another realistic and more severe misspecification to show the potential of SAM in most challenging conditions:
    $$\\boldsymbol{B} = ", beta_latex_1_3, "$$
    - **Model 1.4** in deviation from the preregistration with a bidirectional structural relation between f3 and f4 specified as only one directional instead of just reversing the effect to investigate a different type of misspecification:
    $$\\boldsymbol{B} = ", beta_latex_1_4, "$$")
    ```

- $\boldsymbol{\Psi}$ as $M \times M$ as diagonal matrix representing the residual variances in deviation from the preregistration not adjusted for the varying structural relations. This was only updated in the joint study (study 3) to adjust residual variances of all endogenous factors to accurately reflect the number of regressors
    ```{r, results='asis', echo=FALSE}
    cat(" - **Model 1.1, 1.2, 1.3, and 1.4:**
    $$\\boldsymbol{\\Psi} = ", psi_latex_1, "$$")
    ```

- $\boldsymbol{\Lambda}$ as $P \times M$ matrix representing factor loadings.
    ```{r, results='asis', echo=FALSE}
    cat(" - **Model 1.1, 1.3 and 1.4:**
    $$\\boldsymbol{\\Lambda} = ", lambda_latex_1, "$$")
    ```

    -   **Model 1.2**: cross loadings will be set to be 10% lower than the factor loadings: $\Lambda_{ik,jk} = 0.63 = 0.9 \times 0.7$. They will be generated by the following elements in $\Lambda$: (2, 2), (5, 3), (8, 4), (11, 5), (14, 1).

- $\boldsymbol\Theta$ as a $P \times P$ matrix representing the residual variances and covariances of the indicators.

    - Model 1.1, 1.2 and 1.4: The diagonal generated as: $$\Theta^* = \mathbf{\Lambda} \operatorname{Var}(\boldsymbol{\eta}) \boldsymbol{\Lambda}^T \times \frac{1}{r-1}$$
        (where $r$ is the reliability of the indicators) and 0 on all off-diagonal elements
    - Model 1.3:
        - $\Theta^*$ on the diagonal.
        - Correlated residuals generated between specific indicator pairs: for $i = (2, 5, 8, 11, 14)$ and $i' = (3, 6, 9, 12, 15)$, and for each $k=1,\ldots,4$ and $l=k+1,\ldots,5$, the entries $(i_k, i'_l)$ and $(i'_l, i_k)$ in $\Theta$ are set to $0.6 \times \min \Theta^*$, ensuring correlated errors among selected indicator pairs without exceeding a 0.6 correlation coefficient.

#### 3.1.2. Study 2:

For study 2, again, different population models were generated parametrically. Further, the different models of study 2 were used for different simulation settings resulting in two sub-studies 2.1 and 2.2 (see simulation settings).

- $\boldsymbol{B}$ as $M \times M$ matrix representing latent regression coefficients with varying parameter size defined by two conditions of endogenous factor variance explained by the exogenous factors (low: $R^2 = 0.1$ or medium: $R^2 = 0.4$ see below under factor):

    - **Model 2.1 and 2.2**: $$
          \boldsymbol{B} = \begin{bmatrix} 
          0 & 0 & 0 & 0 & 0 \\
          0 & 0 & 0 & 0 & 0 \\
          0 & 0 & 0 & 0 & 0 \\
          \beta_{\eta_4,\eta_1} & \beta_{\eta_4,\eta_2} & 0 & 0 & 0 \\
          0 & \beta_{\eta_5,\eta_2} & \beta_{\eta_5,\eta_3} & \beta_{\eta_5,\eta_4} & 0 \\
          \end{bmatrix}
          $$

- $\boldsymbol\Lambda$ as $P \times M$ matrix representing factor loadings of indicators on the latent factors.

    - **Model 2.1**: $$
          \boldsymbol\Lambda = \begin{bmatrix}
          1 & 0 & 0 & 0 & 0 \\
          0.9 & 0 & 0 & 0 & 0 \\
          0.8 & 0 & 0 & 0 & 0 \\
          0 & 1 & 0 & 0 & 0 \\
          0 & 0.9 & 0 & 0 & 0 \\
          0 & 0.8 & 0 & 0 & 0 \\
          0 & 0 & 1 & 0 & 0 \\
          0 & 0 & 0.9 & 0 & 0 \\
          0 & 0 & 0.8 & 0 & 0 \\
          0 & 0 & 0 & 1 & 0 \\
          0 & 0 & 0 & 0.9 & 0 \\
          0 & 0 & 0 & 0.8 & 0 \\
          0 & 0 & 0 & 0 & 1 \\
          0 & 0 & 0 & 0 & 0.9 \\
          0 & 0 & 0 & 0 & 0.8 \\
          \end{bmatrix}
          $$

    - **Model 2.2** with cross-loadings either in the exogenous ($\lambda_{6,3}$), endogenous ($\lambda_{12,5}$) or both parts of the model. Which cross loading was present depended on the misspecification simulation factor. The specific magnitude of the endogenous ($\lambda_{12,5}$) loading depended on $R^2$ (see under 3.2.2): $$
          \boldsymbol\Lambda = \begin{bmatrix}
          1 & 0 & 0 & 0 & 0 \\
          0.9 & 0 & 0 & 0 & 0 \\
          0.8 & 0 & 0 & 0 & 0 \\
          0 & 1 & 0 & 0 & 0 \\
          0 & 0.9 & 0 & 0 & 0 \\
          0 & 0.8 & \lambda_{6,3} & 0 & 0 \\
          0 & 0 & 1 & 0 & 0 \\
          0 & 0 & 0.9 & 0 & 0 \\
          0 & 0 & 0.8 & 0 & 0 \\
          0 & 0 & 0 & 1 & 0 \\
          0 & 0 & 0 & 0.9 & 0 \\
          0 & 0 & 0 & 0.8 & \lambda_{12,5} \\
          0 & 0 & 0 & 0 & 1 \\
          0 & 0 & 0 & 0 & 0.9 \\
          0 & 0 & 0 & 0 & 0.8 \\
          \end{bmatrix}
          $$

- $\boldsymbol\Theta$ as a $P \times P$ matrix representing the residual variances and covariances of the indicators. This was computed as the portion of the indicator's total variance that is not explained by the latent factors, after accounting for the strength and reliability of its relationship to these factors (factor loadings), as well as the effects of regressions between the latent factors themselves.

    - **Model 2.1**: The diagonal of $\boldsymbol\Theta$ generated as: $$\Theta^* = \mathbf{\Lambda} \operatorname{Var}(\boldsymbol{\eta}) \boldsymbol{\Lambda}^T \times \frac{1}{r-1}$$
        (where $r$ is the reliability of the indicators) and 0 on all off-diagonal elements
    - **Model 2.2**:
        - $\Theta^*$ on the diagonal.
        - Correlated residuals generated between specific indicator pairs in either the endogenous, exogenous or both parts of the model.

        Thus depending on the simulation setting either:

        - $\Theta_{8,9}$, $\Theta_{9,8}$ (exogenous part)

        - $\Theta_{14,15}$ and $\Theta_{15,14}$ (endogenous part)

        - $\Theta_{8,9}$, $\Theta_{9,8}$, $\Theta_{14,15}$ and $\Theta_{15,14}$ (both parts)

        were set $0.6 \times \min \Theta^*$, ensuring correlated errors among selected indicator pairs without exceeding a 0.6 correlation coefficient:

#### 3.1.3 Study 3:

### 3.2. What will be the different factors of the data-generating mechanism?

#### 3.2.1. Study 1

The first study modulated the following factors:

- **Different misspecifications** of the population model where the population model varies between the different models (1.1, 1.2, 1.3, 1.4) as described above, while the analysis model remains specified as model 1.1.
- **Sample sizes** of small (N = 100), medium (N = 400), or large (N = 6400)
- Indicator reliability of low (.3), moderate (.5), or high (.7)

#### 3.2.2. Study 2:

The second study modulated the following factors of the data generating process across both studies:

- **Sample sizes** of small (N = 100), medium (N = 400), or large (N = 6400)
- **Variance explained** ($R^2$) of the endogenous factor variance explained by the exogenous factors: low ($R^2 = 0.1$) or medium ($R^2 = 0.4$)

In two sub-studies 2.1 and 2.2, the following additional factors will be modulated, respectively:

-  **Study 2.1**:
    - **Indicator reliability** of three indicators per factor: *all high* (.8), *all low* (.5), *average low* (.5) varying between .7 to .3 with the highest reliability for the scaling indicator.
    - **Sample sizes** of small (N = 100), medium (N = 400), or large (N = 6400)
    - Deviating from the preregistration distribution (normal vs. non-normal) was not considered in the simulation settings to limit the scope of the study.
-   **Study 2.2**
    - **Structural misspecifications** by varying the population model as described and thus omitting either
        -   a residual covariance in the exogenous part of the model
        -   a factor loading in the endogenous part of the model
        -   a factor loading in the exogenous part of the model
        -   a structural path in the endogenous part of the model
        -   a structural path in the analysis model.\
    - **Number of measurement blocks** (how many separate measurement models are fitted in the first step of SAM):
        -   Separate measurement model per latent variable (b = k = 5)
        -   Joint measurement model for all exogenous variables (b = 3)

**Explanation of the chosen factor values:**

The aim was a conceptual replication of the results obtained by @rosseel_structural_2022 in study 1 and @dhaene_evaluation_2023 study 2. The values were chosen accordingly. No detailed explanation was provided by the authors.

### If there is more than one factor: How will the factor levels be combined and how many simulation conditions will this create?

-   Study 1:
    -   4 population models x 2 model specifications x 3 sample sizes x 3 reliabilities = 72 conditions
        -   Note: For each of the 4 population models (1.1, 1.2, 1.3, 1.4), two scenarios are considered:
            -   Correctly specified analysis model matching the population model.
            -   Incorrectly specified analysis model, corresponding to model 1.1, with specific misspecifications for models 1.2 (omitted cross-loadings), 1.3 (correlated item residuals), and 1.4 (structural misspecification).
-   Study 2.1:
    -   2 population models (2.1, 2.2) x 3 sample sizes x 3 reliabilities x 2 distributions = 36 conditions
-   Study 2.2:
    -   2 population models x 3 sample sizes x 5 misspecifications = 30 conditions

## 4. Estimands and Targets

### Estimands

Structural model parameters (path coefficients)

## 5. Methods

Both studies will compare four different estimation methods for SEMs:

-   **"Vanilla" SEM**: (structural and measurement model estimated simultaneously) (rationale: the current standard approach in SEM estimation serving as a baseline with maximum likelihood (ML)):
-   **SAM**: (separating the estimation of the measurement and structural model to alleviate the potential for propagation of bias from (e.g. misspecified) measurement part to the structural part of the model)
    -   **Local SAM** (Uses summary statistics from the measurement model to derive the model-implied mean vector and variance-covariance matrix of latent variables. These statistics are then utilized to estimate the structural parameters. A mapping matrix (M) is used to transform the observed data into the latent variable space. It can be estimated using different methods.)
        -   **With ML mapping matrix** (Akin to a factor score approach (@bartlett_statistical_1937, @bartlett_methods_1938))
        -   **With ULS mapping matrix** (Uses the Moore-Penrose pseudoinverse, suitable for scenarios with complex or underdetermined systems, where the K matrix is rank-deficient but requires adjustments for structural constraints.)
    -   **Global SAM** (rationale: Fixing the parameters obtained from the measurement model in the first step, and then using them as constants in the full SEM during the second step. Suitable for models where local SAM is impractical due to higher-order latent variables or rank deficiencies in $\lambda$.)

"Vanilla" SEM as well as both steps in the SAM approach will be estimated using Maximum Likelihood (ML) using the `lavaan` (@rosseel_lavaan_2012) package in R (@r_core_team_r_2023).

## 6. Performance Measures

Across both studies the following performance measures will be captured:

-   Convergence rates: Proportions of observed data sets that successfully converged for each estimation method.
-   Empirical relative biases: Average difference between an estimate and its true value, normalized by the true value, assessed across all path coefficients.
-   Empirical coverage levels of 95% confidence intervals (CIs): Proportion of observed data sets where the constructed CIs included the true value.
-   Root Mean Squared Errors (RMSE): Calculated as the square root of the average squared difference between an estimate and its true value, evaluated under conditions of model misspecification.

### How will Monte Carlo uncertainty of the estimated performance measures be calculated and reported?

Monte Carlo uncertainty will be calculated using the `simhelpers` (@noauthor_helper_nodate) package in R as Monte Carlo Standard Errors (MCSEs):

For the bias: $$
\sqrt{S_T^2 / K}
$$

For the RMSEA: $$
\sqrt{\frac{K-1}{K} \sum_{j=1}^K\left(R M S E_{(j)}-R M S E\right)^2}
$$

$$
S_T^2=\frac{1}{K-1} \sum_{k=1}^K\left(T_k-\bar{T}\right)^2
$$

### How many simulation repetitions will be used for each condition?

-   Replicating @rosseel_structural_2022 study 1 will consist of 5000 repetitions per condition.
-   Replicating @dhaene_evaluation_2023 study 2 will consist of 10000 repetitions per condition.

### How will missing values due to non-convergence or other reasons be handled?

As mentioned above the convergence rates will be captured and evaluated.

### How do you plan on interpreting the performance measures? (optional)

The results will be interpreted in comparison to the results and interpretations obtained by @dhaene_evaluation_2023 and @rosseel_structural_2022.

### Which statistical software/packages do you plan to use?

The simulation will be set up in @r_core_team_r_2023 using the `lavaan` package for generating data based on the population models as well as for applying SEM estimation methods (@rosseel_lavaan_2012) as well as the `furrr` (@davis_furrr_2022) package for parallel simulation execution.

### Which computational environment do you plan to use?

The simulation will run on a high performance computing cluster using @noauthor_tardis_nodate with @noauthor_future_nodate and @heidilohr_azure_nodate

### Which other steps will you undertake to make simulation results reproducible? (optional)

The code of the simulation will be made available on GitHub

(https://github.com/valentinkm/AdversarialSimulation)