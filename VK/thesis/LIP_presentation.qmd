---
title: "Adversarial Simulation"
subtitle: "Structural after Measurement vs. vanilla SEM estimation - a case study on adversarial collaboration for simulation studies"
fig-cap-location: top
format:
  revealjs:
    center: true
    theme: default
    slide-number: c/t
    font-size: 12pt
    chalkboard: true

engine: knitr
bibliography: ../../bibliography.bib
---
```{r, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = FALSE)

library(dplyr)
library(tidyr)
library(kableExtra)
library(ggplot2)
library(data.table)
library(dplyr)
library(tidyr)
library(ggh4x)


```


::: {.r-fit-text style="font-size: 0.8em;"}
## Outline {auto-animate=true}
1. "Angry Science" and the Generalizability Challenge
2. Adversarial Collaboration as one Remedy
3. An Adversarial Simulation Framework
<br>
<br>
<span style="color: grey;">Time for questions</span>
<br>
<br>
4. **Background**: SAM vs. SEM
5. **Findings**: Results and Collaboration
6. **Outlook**: Evaluation and Future Directions
<br>
<br>
<span style="color: grey;">Discussion</span>

:::


## 1. The Generalizability Challenge {auto-animate=true}
:::{.columns}
::: {.column width="0%"}
::: {.r-fit-text}
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
:::
:::
::: {.column width="50%"}
::: {.r-fit-text}
```{dot}
digraph circular_process {
    // Use 'neato' layout for positioning
    layout=neato;
    overlap=false;
    splines=true;

    // Define global node attributes
    node [shape=plaintext, fontsize=12];

    // Define nodes with positions to form a circle
    hypothesize [label="Hypothesize", pos="0,1!"];
    operationalize [label="Operationalize", pos="-0.866,-0.5!"];
    gather_data [label="Gather Data", pos="0.866,-0.5!"];

    // Define edges to create a circular process
    hypothesize -> operationalize;
    operationalize -> gather_data;
    gather_data -> hypothesize;
}
```

:::
:::
:::


## 1. The Generalizability Challenge {auto-animate=true}

:::{.columns}
::: {.column width="25%"}
::: {.r-fit-text}

<br>
general & verbal
<br>
<br>
<br>
<br>
<br>
researchers degrees of freedom
<br>
<br>
<br>
<br>
<br>
specific & empirical
:::
:::
::: {.column width="50%"}
::: {.r-fit-text}
```{dot}
digraph circular_process {
    // Use 'neato' layout for positioning
    layout=neato;
    overlap=false;
    splines=true;

    // Define global node attributes
    node [shape=plaintext, fontsize=12];

    // Define nodes with positions to form a circle
    hypothesize [label="Hypothesize", pos="0,1!"];
    operationalize [label=< <font color="red">Operationalize</font> >, pos="-0.866,-0.5!"];
    gather_data [label=< <font color="red">Gather Data</font> >, pos="0.866,-0.5!"];

    // Define edges to create a circular process
    hypothesize -> operationalize;
    operationalize -> gather_data;
    gather_data -> hypothesize;
}
```
:::
:::
:::


## 1. The Generalizability Challenge {auto-animate=true}

:::{.columns}
::: {.column width="25%"}
::: {.r-fit-text}

<br>
general & verbal
<br>
<br>
<br>
<br>
<br>
researchers degree of freedom
<br>
<br>
<br>
<br>
<br>
specific & empirical
:::
:::
::: {.column width="50%"}
::: {.r-fit-text}
```{dot}
digraph circular_process {
    // Use 'neato' layout for positioning
    layout=neato;
    overlap=false;
    splines=true;

    // Define global node attributes
    node [shape=plaintext, fontsize=12];

    // Define nodes with positions to form a circle
    hypothesize [label="Method A over B?", pos="0,1!"];
    operationalize [label=< <font color="red">Population Model X etc.</font> >, pos="-0.866,-0.5!"];
    gather_data [label=< <font color="red">Simulate</font> >, pos="0.866,-0.5!"];

    // Define edges to create a circular process
    hypothesize -> operationalize;
    operationalize -> gather_data;
    gather_data -> hypothesize;
}
```
:::
:::
:::

## 2. Adversarial Collaboration as one Remedy {auto-animate=true}
:::{.r-fit-text}
:::{.columns}
::: {.column width="50%"}
### The Mapping Challenge
- Science is **communicated** through **general verbal descriptions**.
- Empirical research, however, requires **precise operationalization** on the empirical plane.
- Conflicts arise when **verbal descriptions** do not neatly map onto operationalized data.
- This leads to **persistent disagreements** and **ambiguity** in scientific discourse.

**Adversarial Collaboration** steps in to **bridge this gap**:
:::

::: {.column width="50%"}
### How Adversarial Collaboration Works
#### 1. Identifying the Disagreement
- Scholars with opposing views **jointly identify** where their verbal descriptions and empirical evidence diverge.

#### 2. Creating a Shared Language
- **Translate** general verbal descriptions into mutually agreed **operational definitions**.
- This **mapping** is key: aligning theoretical concepts with empirical measures.

#### 3. Designing Mutual Tests
- Develop **agreed-upon methods** to test competing hypotheses, focusing on points of empirical disagreement.
- Tests must capture both the **nuances** of verbal claims and the **rigor** of empirical standards.

#### 4. Joint Interpretation of Results
- Both sides **collaborate** in interpreting the findings, ensuring that conclusions **respect the initial verbal intentions** while reflecting **empirical reality**.

:::

:::{.column width="100%"}
### Addressing the Challenge
- **Unveils Ambiguity**: Forces researchers to clarify verbal claims through precise, shared operational definitions.
- **Promotes Accountability**: Mutual design and interpretation prevent biases stemming from unclear mappings.
- **Strengthens Generalizability**: By rigorously debating and aligning verbal-empirical mappings, findings gain broader applicability.

*“Adversarial Collaboration acts as a translator between science's verbal world and its empirical reality.”*
:::
:::
:::


## Creating an Adversarial Simulation <span style="color:#4682B4;">Framework</span>{auto-animate=true}

## <span style="color:#4682B4;">Structure</span> of a Simulation Study {auto-animate=true}

::: {.r-fit-text}
| Steps of a Simulation Study | Content |
|-----------------|-----------------|
| <span class="fragment">1. Research Question</span>    | <span class="fragment">Verbal description of research goals</span>    |
| <span class="fragment">2. Population Model</span>   | <span class="fragment">Type, size, complexity</span> |
| <span class="fragment">3. Data Generation</span>    | <span class="fragment">E.g. resampling vs. parametric draw</span>    |
| <span class="fragment">4. Experimental Design</span>    | <span class="fragment">Specifiy conditions (e.g. sample size)</span>    |
| <span class="fragment">5. Method Selection</span>   | <span class="fragment">Type, implementation, number</span>    |
| <span class="fragment">6. Estimands</span>    | <span class="fragment">Population level parameter values</span>    |
| <span class="fragment">7. Performance Metrics</span>    | <span class="fragment">E.g. Bias, Coverage etc.</span>  |
| <span class="fragment">8. Software</span>    | <span class="fragment">Applies to steps 2-7</span>    |
| <span class="fragment">9. Analysis</span>    | <span class="fragment">Decision criteria, graphical display etc.</span>  |
:::

## A <span style="color:#4682B4;">Structured</span> Adversarial Simulation <span style="color:#4682B4;">Framework</span> {auto-animate=true}

::: {.r-fit-text}
|                     | Round 1         | Round 2               | Round 1         |
|---------------------|:---------------:|:---------------------:|:---------------:|
| Steps         | Collaborator 1  | Joint Study           | Collaborator 2  |
|1. Research Question|                |  Agreed upon prior to Round 1 |                |
| 2. Population Model |→                |                       |←                |
| 3. Data Generation  |→                |                       |←                |
| 4. Experimental Design|→              |                       |←                |
| 5. Method Selection |→                |                       |←                |
| 6. Estimands        |→                |                       |←                |
| 7. Performance Metrics|→             |                       |←                |
| 8. Software         |→                |                       |←                |
| 9. Analysis         |→                |                       |←                |
:::


## SAM vs SEM <span style="font-size: 20px;"> Background</span>

## Standard SEM Estimation <span style="font-size: 20px;">(e.g.ML, ADF, GLS, ULS)</span>{auto-animate="true"}

::: {.columns}
:::: {.column width="50%"}
![](figures/model0.svg){width="100%"}
::::

:::: {.column width="50%"}
::: {.r-fit-text}
::: {.fragment .fade-in-then-out}
-  e.g. normal theory-based maximum likelihood (ML) discrepancy function
- System-wide parameter ($\vartheta$) optimization
- Assumes multivariate normal distribution
:::
:::{.fragment .fade-in}
Problems:

- non-convergence issues 
- improper solutions
- bias due to local measurement misspecifications propagating to all model parameters
- requiring large sample sizes for optimal statistical properties.
:::
:::
::::
:::


## Structural After Measurement (SAM)
::: {.columns}
:::: {.column width="50%"}
<img src="figures/model0_1.svg" width="80%">
::::

:::: {.column width="50%"}
::: {.r-fit-text}
**Two-phase process:**

1. <span style="color: red;">$\vartheta_1$: Measurement model</span> <br>
    <span class="fragment">**Local SAM (lSAM):**</span> <br>
    <span class="fragment">Separate "measurement blocks"</span><br>
    <span class="fragment">Latent summary statistics and mapping matrix;</span> <br>
    <span class="fragment">**Global SAM (gSAM):** Fixed measurement parameters for the entire measurement model.</span>

:::{.fragment}
<br>
 → 
<br>

:::
2. <span style="color: blue;">$\vartheta_2$: Structural model</span>
:::
::::
:::

:::{.notes}
1. **Local SAM (lSAM):** Constructs the latent variable mean vector and variance-covariance matrix using observed data, measurement parameters, and a mapping matrix to inform the structural model estimation.

2. **Global SAM (gSAM):** Directly estimates structural parameters using the full model while keeping measurement parameters fixed, without constructing latent variable summary statistics.
:::


## SAM vs. SEM: <br> Disagreeing Reports {auto-animate="true"}
::: {.r-fit-text}
| @rosseel_structural_2022, @dhaene_evaluation_2023 | @robitzsch_comparing_2022 |
|------------------------------|---------------------------|
| - SAM outperformed SEM in terms of convergence, bias & RMSE in small samples x low item reliability, especially under misspecifications <br> | - SAM did not generally outperform traditional SEM in challenging conditions. <br> - SAM appears better: general negative small sample bias of SAM cancels out positive bias from positive misspecifications. |
<br>
<br>

:::{.fragment}
<div style="text-align: center;">
**→ Basis for a case study on adversarial collaboration**
</div>

:::

:::

## SAM vs. SEM: <br> an <span style="color: #4682B4;"> Adversarial Simulation </span> {auto-animate="true"}
::: {.r-fit-text}
| @rosseel_structural_2022, @dhaene_evaluation_2023 | @robitzsch_comparing_2022 |
|------------------------------|---------------------------|
| - SAM outperformed SEM in terms of convergence, bias & RMSE in small samples x low item reliability, especially under misspecifications <br> | - SAM did not generally outperform traditional SEM in challenging conditions. <br> - SAM appears better: general negative small sample bias of SAM cancels out positive bias from positive misspecifications. |
| <span style="color: #4682B4;">**Replication by Kriegmair**</span> | <span style="color: #4682B4;">**Replication by Kosanke**</span>|
<br>
<br>


<div style="text-align: center;">
**→ Basis for a case study on adversarial collaboration**
</div>

:::

## 5. Findings of the Case Study

Replication Results
<br>
Adversarial Collaboration

## Round 1: Individual Studies 
| Kriegmair | Kosanke |
|-----------------|-----------------|
| based on @rosseel_structural_2022 and @dhaene_evaluation_2023 | based on @robitzsch_comparing_2022  |

## Studies by Kriegmair

## Study 1 <span style="font-size: 20px;">based on @rosseel_structural_2022</span>

::: {.r-fit-text}
::: {layout="[20,60,20]"}

::: {.column width="0%"}
:::

::: {.column width="60%"}

::: {layout="[[1,1], [1,1]]" layout-valign="top"}

::: {.column width="50%" .fragment}
1.1 <span style="font-size: 20px;">no misspecifications</span>
![](figures/model1_1.svg){width="60%"}
:::

::: {.column width="50%" .fragment}
1.2 <span style="font-size: 20px;"> cross loadings</span>
![](figures/model1_2.svg){width="60%"}
:::

::: {.column width="50%" .fragment}
1.3 <span style="font-size: 20px;"> correlated residuals </span>
![](figures/model1_3.svg){width="80%"}
:::

::: {.column width="50%" .fragment}
1.4 <span style="font-size: 20px;"> structural misspecification </span>
![](figures/model1_4.svg){width="60%"}
:::
:::
:::

::: {.column width="35%" .fragment}
#### Other Conditions:

- *N*: 100, 400, 6400
- Indicator reliability: 0.3, 0.5, 0.7

#### Methods:

- Vanilla SEM with Maximum Likelihood (ML)
- Global SAM (gSAM)
- Local SAM (lSAM-ML)
- Local SAM with unweighted least squares (lSAM-ULS)

#### Performance Metrics:
- Bias of path estimates
- RMSE of path estimates
- Coverage of 95% CI for path estimates

:::
:::
:::

## Study 2 <span style="font-size: 20px;">based on @dhaene_evaluation_2023</span>

::: {.r-fit-text}
::: {layout="[[45,10,10,35]]" layout-align="top"}

::: {.column width="45%"}
::: {layout="[[1,1]]" layout-valign="top"}

::: {.column width="50%" .fragment}
#### 2.1:

- No measurement misspecifications
- Estimated paths absent in population

![](figures/model2_1.svg){width="100%"}
:::

::: {.column width="50%" .fragment}
#### 2.2:

- Estimated paths absent in population
- <span style="color: orange;">In exogenous analysis model</span>
- <span style="color: green;">In endogenous analysis model
![](figures/model2_2.svg){width="100%"}
:::
:::
:::
::: {.column width="7%"}
<!-- Empty column for space -->
:::

::: {.column width="35%"}
::: {.fragment}
#### Other Conditions:

- *N*: 100, 400, 6400
- Indicator reliability: 0.3, 0.5, 0.7
- **$R^2$: 0.1, 0.4**
- **Measurement blocks: 3, 5**
:::


:::{.fragment}
#### Methods:

- Vanilla SEM
- Global SAM
- Local SAM
- Local SAM with unweighted least squares

### Repetitions: 
- 10000
:::

:::
:::
:::

## Studies by Kosanke <span style="font-size: 20px;">based on @robitzsch_comparing_2022</span>

![](figures/kosanke_studies_overview.png)

# Results of individual studies:

## Convergence Rate
::: {.r-fit-text}
| | Kriegmair | Kosanke |
|--------|----------------|-------------|
| Verbal Dispute |low convergence rate of SEM| no convergence issues |
|Method selection|un-bounded ML SEM |bounded ML SEM |
|Analysis| condition-wise rates | global rate |
|| direct:<br>`lavInspect(fit, "converged")` | indirect:<br>`quietly(safely(simulation_study_))`|
:::

## Convergence Rate <span style="font-size: 20px;"> E.g.: Kriegmair Study 1:</span>

![](tables/convergence_rate_study1.png)

## Bias
::: {.r-fit-text}
| | Kriegmair | Kosanke |
|------|-----------|---------|
| Verbal Dispute |"SEM performes worse than SAM in low reliability x low sample size x misspecification"| "SAM generally did not outperform traditional SEM in small to moderate samples." <br> <br> "[under] unmodelled negative cross-loadings and residual correlations, SAM tended to perform worse than traditional SEM"|
:::




## Bias <span style="font-size: 20px;"> E.g.: Kriegmair Study 1: absolute $\hat{\beta}$ bias values aggregated across parameters</span>
::: {.r-fit-text}
![](tables/aggregated_bias_study1.png)
:::


## Bias <span style="font-size: 20px;"> E.g.: Kosanke Study 1:</span>
::: {.r-fit-text}
```{r eval = TRUE, echo = FALSE}

# Load the relative bias results
bias_ci_s1 <- readRDS("../../LK/SimulationResultsProcessed/sim1_rel_bias_ci.rds")

shorten_names <- function(df) {
  df$method_metric <- sub("_rel_bias", "", df$method_metric)
  return(df)
}

# Function to create a styled table for each condition
create_styled_table <- function(data, condition) {
  data <- shorten_names(data)
  data <- data %>%
    mutate(across(where(is.numeric), ~ round(., 3)))
  
  # Format table
  kbl(data,
      col.names = c("Method", "50", "100", "250", "500", 
                    "1000", "2500", "100000"), booktabs = TRUE) %>%
    kable_styling(full_width = T, position = "left") %>%
    add_header_above(c(" " = 1, "Sample Size" = 7)) %>%
    column_spec(1, width = "3.5cm") %>% 
    row_spec(0, bold = TRUE) %>%
    kable_classic(full_width = F) %>%
    gsub("_", " ", .)
}
create_styled_table(bias_ci_s1[["2_-0.12"]], "2_-0.12")
```

<span style="font-size: 22px;">Relative bias of $\hat{\phi}$ in conditions with two negative unmodelled residual correlations in a 2-factor-CFA</span>

:::


## Bias
::: {.r-fit-text}
| | Kriegmair | Kosanke |
|------|---------|-----------|
| Verbal Dispute |"SEM performs worse than SAM in low reliability x low sample size x misspecification"| "SAM generally did not outperform traditional SEM in small to moderate samples." <br> <br> "[under] unmodeled negative cross-loadings and residual correlations, SAM tended to perform worse than traditional SEM"|
|4. Experimental Design| *N*:100-6400 <br> Reliability via Θ <br> Positive cross loadings & correlated residuals| *N*:50-100000 <br> Reliability via $\lambda$ <br> Positive & negative cross loadings and correlated residuals (only in CFA)|
| &nbsp;                  | &nbsp;       | &nbsp;                       |
| &nbsp;                  | &nbsp;       | &nbsp;                                  |
:::
:::{.notes}
In Kosanke’s results, SAM appears to perform worse than traditional SEM under unmodeled negative cross-loadings and residual correlations. This happens because of bias cancellation in LSAM, particularly in small samples.

LSAM tends to have a negative small-sample bias, and when you ignore positive residual correlations, that introduces a positive bias. These two biases can accidentally cancel each other out, making LSAM seem more accurate than it really is.

However, this is a false perception of robustness, as LSAM performs inconsistently across different conditions, and in cases like unmodeled negative correlations, it actually does worse than SEM. Kosanke's study shows that SAM doesn’t generally outperform traditional SEM in small to moderate samples, especially when negative biases are present.
:::

## Bias
::: {.r-fit-text}
| | Kriegmair | Kosanke |
|------|---------|-----------|
| Verbal Dispute |"SEM performs worse than SAM in <span style="color: green;">low reliability</span> x <span style="color:blue;">low sample size</span> x <span style="color:orange;">misspecification</span>"| "SAM generally did not outperform traditional SEM in <span style="color:blue;">small to moderate samples</span>." <br> <br> "[under] <span style="color:orange;">unmodeled negative cross-loadings and residual correlations</span>, SAM tended to perform worse than traditional SEM"|
|4. Experimental Design| *N*:<span style="color:blue;">100, 400</span>, 6400<br> <span style="color:green;">Reliability via $\Theta$ </span> <br> <span style="color:orange;">Positive cross loadings & correlated residuals</span>| *N*:<span style="color:blue;">50, 100, 250, 500</span>, 1000, 2500, 100000<br><span style="color:green;"> Reliability via  $\Lambda$</span> <br> <span style="color:orange;">Positive & negative cross loadings & correlated residuals (only in CFA)</span>|
|<span class = "fragment"> 5. Population Model</span >|<span class = "fragment"> 5-factor-SEM</span>| <span class="fragment"> 2-factor CFA & 5-factor SEM </span> |
|<span class = "fragment"> 6. Analysis |<span class = "fragment"> Aggregated absolute values and parameter-wise </span> |<span class = "fragment"> Aggregated absolute values & aggregated relative bias </span> |
:::


## Collaboration
<div class="scrollable-table">
<table>
  <thead>
    <tr>
      <th></th>
      <th>Round 1</th>
      <th>Round 2</th>
      <th>Round 1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Steps</strong></td>
      <td>Kriegmair</td>
      <td>Joint Study</td>
      <td>Kosanke</td>
    </tr>
    <!-- Step 2 -->
    <tr>
      <td><strong>Population Model</strong></td>
      <td>
        5-factor-SEM
      </td>
      <td class="fragment" data-fragment-index="2">5-factor-SEM</td>
      <td>
        5-factor-SEM<br>
        <span class="strike fragment" data-fragment-index="2">2-factor-CFA</span>
      </td>
    </tr>
    <!-- Step 3 -->
    <tr>
      <td><strong>Data Generation</strong></td>
      <td>
        parametric & normally distributed
      </td>
      <td class="fragment" data-fragment-index="3">parametric & normally distributed</td>
      <td>
        parametric & normally distributed
      </td>
    </tr>
    <!-- Step 4 -->
    <tr>
      <td><strong>Experimental Design</strong></td>
      <td>
        <span class="strike fragment" data-fragment-index="4">Misspecifications (+)</span><br>
        *N*: 100 - <span class="strike fragment" data-fragment-index="4">6400</span><br>
        Reliability via Θ
      </td>
      <td class="fragment" data-fragment-index="4">
        Misspecifications (+/-)<br>
        *N*: 50, 100, 250, 400<br>
        Reliability via Θ
      </td>
      <td>
        Misspecifications (+/-)<br>
        *N*: 50 - <span class="strike fragment" data-fragment-index="4">100,000</span><br>
        <span class="strike fragment" data-fragment-index="4">Reliability via λ</span>
      </td>
    </tr>
    <!-- Step 5 -->
    <tr>
      <td><strong>Method Selection</strong></td>
      <td>
        SEM-ML, gSAM, lSAM (ULS & ML)
      </td>
      <td class="fragment" data-fragment-index="5">
        SEM-ML, gSAM, lSAM (ULS & ML)
      </td>
      <td>
        SEM (<span class="strike fragment" data-fragment-index="5">ML</span> & ULS), gSAM, lSAM (ULS & ML)
      </td>
    </tr>
    <!-- Step 6 -->
    <tr>
      <td><strong>Estimands</strong></td>
      <td>
        β: Fixed at 0.1 <span class="strike fragment" data-fragment-index="6"> and varied</span>
      </td>
      <td class="fragment" data-fragment-index="6">
        β: Fixed at 0.1
      </td>
      <td>
        β: Fixed at 0.1<br>
        <span class="strike fragment" data-fragment-index="6">φ: Fixed and varied</span>
      </td>
    </tr>
    <!-- Step 7 -->
    <tr>
      <td><strong>Performance Metrics</strong></td>
      <td>
        Absolute bias in absolute values <br>
        RMSE<br>
        95% CI coverage<br>
        Convergence & Improper Solutions
      </td>
      <td class="fragment" data-fragment-index="7">
        Absolute bias<br>
        RMSE<br>
        95% CI coverage<br>
        Convergence & Improper Solutions
      </td>
      <td>
        Absolute bias in absolute values<br>
        <span class="strike fragment" data-fragment-index="7">Relative bias</span><br>
        RMSE<br>
        95% CI coverage      </td>
    </tr>
    <!-- Step 8 -->
    <tr>
      <td><strong>Software</strong></td>
      <td>
        lavaan::simulateData()
      </td>
      <td class="fragment" data-fragment-index="8">
        lavaan::simulateData()
      </td>
      <td>
        lavaan::simulateData()
      </td>
    </tr>
    <!-- Step 9 -->
    <tr>
      <td><strong>Analysis</strong></td>
      <td>
        Aggregated across parameters,<br> heat maps
      </td>
      <td class="fragment" data-fragment-index="9">
        Aggregated, <br> **parameter-wise**,<br>
        decision criteria <br> heat maps
      </td>
      <td>
        Aggregated across parameters,<br> decision criteria
      </td>
    </tr>
  </tbody>
</table>
</div>

<style>
  .scrollable-table {
    max-height: 65vh;
    overflow-y: auto;
    font-size: 0.6em;
  }
  .scrollable-table table {
    border-collapse: collapse;
    width: 100%;
  }
  .scrollable-table th, .scrollable-table td {
    border: 1px solid #ddd;
    padding: 4px;
    text-align: left;
  }
  .scrollable-table th {
    background-color: #f2f2f2;
    position: sticky;
    top: 0;
  }
  .strike {
    text-decoration: none;
  }
  .strike.visible {
    text-decoration: line-through;
  }
</style>

<script>
  // Auto-scroll logic
  const scrollableTable = document.querySelector('.scrollable-table');
  let scrollSpeed = 1; // Adjust this for faster/slower scrolling
  
  function autoScroll() {
    if (scrollableTable.scrollTop + scrollableTable.clientHeight >= scrollableTable.scrollHeight) {
      scrollableTable.scrollTop = 0;
    } else {
      scrollableTable.scrollTop += scrollSpeed;
    }
  }
  
  // Set timeout for scrolling to start after 30 seconds
  setTimeout(() => {
    // Set interval for scrolling
    let scrollInterval = setInterval(autoScroll, 50); // 50ms interval, adjust for smoothness
  }, 30000); // 30 seconds delay (30,000 milliseconds)
</script>


:::{.notes}
Adjusting the $\Theta$ matrix directly controls reliability by manipulating measurement error, aligning with its definition as the proportion of variance explained by the latent factor. Modulating $\lambda$ indirectly affects reliability but conflates factor strength with error variance, making it less precise in controlling reliability by definition.
:::

## References