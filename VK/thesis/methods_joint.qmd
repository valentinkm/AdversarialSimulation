\setlength{\parindent}{1.27cm}
After collaborating based on the individually conducted studies and the respective results, we did not jointly arrive at the conclusion that conducting a collaborative simulation study as planned was warranted. However, I identified several reasons for setting up another simulation. Firstly, to test and evaluate the viability and technical feasibility of AC for simulation studies, setting up a study based on individual studies and their results with Kosanke can provide valuable information.

#### Aims, objectives and research questions

Following our framework for collaboration the research questions for the joint study remains the same as specified prior to the individual studies.

#### Population Models and Data Generation Mechanisms

As in my individually conducted studies 1 and 2 (Collaborator A, Kriegmair) data for this *joint* study was generated based on a 5-factor population structural model with 3 indicators for each factor. 
Factor loadings and indicator reliability was computed in the same way as in my first study. Two different population models were simulated, which resulted in misspecifications of either omitted crossloadings (model 3.1) or omitted correlated residuals (model 3.2). The population-level values of the structural parameters were set to 0.1. Reliability levels were manipulated as in my first study by adjusting the measurement error variances (instead of Kosanke's approach of factor loadings modulation) to achieve a more valid representation of item reliability as the amount of indicator variance explained by the latent factor.
The omitted crossloadings (see Figure 4) could either be all positive or negative and were set to be 10% lower in absolute values than the factor loadings. Correlated residuals were also either all positive or all negative and were set to not exceed a factor of 0.6 of the residual variances of the indicators.
Thus, this represents a sufficiently complex model with directed structural paths of interest as a prototypical scenario for which SAM promises to be advantageous, including negative misspecified measurement parameters to test the robustness of SAM to such misspecifications. No CFA models, as in Kosanke's (Collaborator B) studies, were included as SAM is intended to be applied to models with a directed structural part of interest in the presence of misspecifications (@rosseel_structural_2022, @dhaene_evaluation_2023).

::: {#fig-combined-models3}
```{r, echo=FALSE}
#| layout: "[[1,1]]"
#| out.width: "100%"
#| out.height: "100%"
knitr::include_graphics(c("figures/model3_1.tex", 
                          "figures/model3_2.tex"))
```

\raggedright \textit{Note.} Error terms are not explicitly shown in the figure. Dashed lines represent relations omitted in the estimation model present in the population model. Unspecified cross-loadings and correlated residuals could be either positive or negative, resulting in two modulations of models 3.1 and 3.2 in the study.

Population Model Variations for Study 3
:::

#### Experimental Design of simulation procedures

The joint study varied three conditions: (1) sample sizes of very small ($N = 50$), small ($N = 100$), moderate ($N = 400$) and large ($N = 6400$). (2) Indicator reliability of low ($= 0.3$), moderate ($0.5$) or high ($= 0.7$); (3) Model misspecifications with not-specified cross-loadings in the population model that were positive or negative (see figure ) or not-specified correlated residuals in the population model that were positive or negative (see Figure 4). Thus, negative misspecifications were here included in a more complex model with directed structural paths of interest, modulating reliability as before but with a more comprehensive (lower) range of sample sizes as in my studies. 

#### Method Selection

Four estimation methods were compared in this study: bound SEM-ML (with factor and residual variances constrained to be positive), unbound SEM-ML, gSAM (also with ML estimation of the structural model) and lSAM-ML. The choice of these methods was based on the results of the individual studies to (1) observe the effect of constraining the analysis model for standard SEM and (2) directly compare this to unbound standard SEM estimation and the SAM methods. To limit the computational scope and narrow down the comparison, SAM-ULS and SEM-ULS were not included as ULS estimation is mainly aimed to provide robust estimates in conditions of non-normal data distribution, which were not simulated in this study, and it was, based on our previous results, not expected to outperform SAM-ML in this study.

#### Performance Measures

The bias and RMSE of the estimated factor correlations were calculated as in the individual studies and averaged (using absolute values) over all parameters in one model for each condition. Further, to better investigate a potential negative bias that Kosanke (based on @robitzsch_comparing_2022) was assuming for SAM in the presence of negative measurement misspecifications, bias values were analyzed parameterwise to investigate negative bias values without cancellation due to averaging.

#### Software

As in the individual studies by both collaborators, the simulation was conducted in R version 4.4 (@r_core_team_r_2023). The same (parallelizable and dockerized) setup as in my studies was used with a pre-generated set of seeds for reproducibility. The simulation scripts are available on [GitHub](https://github.com/valentinkm/AdversarialSimulation).

#### Analysis and Interpretation Plan

The analysis was conducted largely in the same way as in the individual studies with the adddition of a display of parameter-wise bias values and a  direct difference between metrics of SEM and SAM.