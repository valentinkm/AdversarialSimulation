Here Collaborator B's (Kosanke) studies are presented verbatim from his report (Git commit SHA [3e7f706](https://github.com/valentinkm/AdversarialSimulation/blob/3e7f706d25bcaf9dbe3f6748377eba076e7cc40d/LK/thesis.qmd#L1032C1-L1128C55)): *The structure of this section closely aligns to our agreed upon structure of simulation studies [â€¦]. In a first step, I published a simulation protocol containing all the planned analysis to be replicated from the original paper by @robitzsch_comparing_2022.* 
*This protocol can be accessed here:* <https://github.com/lkosanke/AdversarialSimulation/blob/main/LK/simulation_protocol.pdf>.

#### *Aims, objectives and research questions*

*For my individual study, I replicated parts of @robitzsch_comparing_2022 that were relevant to our two substantive research questions. Overall, I conducted 6 simulation studies.*

#### *Population Models and Data Generation Mechanisms*

*The most important details with regards to the population models and data-generating mechanisms are visible in Table 7.
With regards to the population models, all factors in all studies loaded onto 3 indicators each.
I chose the population values to align with the original paper by @robitzsch_comparing_2022.
The multivariate normally distributed data was generated parametrically, based on a specified population model.
All simulations were conducted using seeds to allow for the reproducibility of results.
For more details on the exact values of each study, see the simulation scripts in the Github repository.*

\vspace{0.5\baselineskip}

::: {fig-kosanke-studies}
```{r fig.cap="Overview of Simulation Studies Conducted by Kosanke\\label{tbl:studies-kosanke}", echo=FALSE, out.width="100%"}
knitr::include_graphics("../../LK/images/TableOverviewIndividualStudies.pdf")
```

\raggedright

\textit{Note.} $\Phi$: factor correlation, N: sample size, $\lambda$: factor loading, $\sigma$: residual variance, $\tau$: factor variance, RC: residual correlations, CL: cross-loadings, CFA: confirmatory factor analysis, $\beta$: regression coefficient between factors.
:::

#### *Experimental Design of simulation procedures*

*Overall, 3 different types of factors were varied that can be deduced from Table 7 and are detailed again in the simulation scripts provided.
Firstly, I varied the sample size in all studies, ranging from N = 50 to 100.000.
I included a smaller sample size N=50 for all studies, to be able to answer our substantive research questions in more detail.
Study 1b explicitly investigated the small sample bias of LSAM estimation in low sample sizes. 
Thus, only N=50 and N=100 were present in this study.
Additionally, I varied the amount of misspecification in all studies, either via different numbers of unmodelled residual correlations, cross-loadings, or both.
Thirdly, in Studies 1b and 4a, I varied the population values for three model parameters (phi, beta and/ or lambda).
Besides studies 1 and 2, I implemented full factorial designs.
In Studies 1 and 2 I omitted conditions were both one positive and one negative value would be present.
I hypothesize that this was done in @robitzsch_comparing_2022 to avoid cancellation of biases, but the authors did not give reasoning for this decision themselves.
In Studies 4 and 4a I investigated the differential performance of the estimators in a model that included a non-saturated structural model (i.e. regressions between some of the factors).
These studies were replications not only of the paper by @robitzsch_comparing_2022, but of the first paper on the SAM approach by @rosseel_structural_2022.
In contrast to the other studies, studies 4 and 4a differed in the way the misspecification variation was labelled in @robitzsch_comparing_2022.
Instead of varying a factor misspecification as in the previous study, they varied 3 different data-generating mechanisms (DGM's) as a whole.
Thus the conditions are labelled differently:
DGM 1 contained no misspecification. DGM 2 contained 5 cross-loadings in the data-generating model, that were not modelled in the estimated models. 
DGM 3 contained 20 residual correlations that were not modelled in the models.
I extended them to investigate the interaction of beta and N for the 5-factor regression model, as this again was of interest four our substantial research questions.
Additionally, I omitted the inclusion of DGM 1 in Study 4a, as it neither contained misspecification (which is central to our research question), nor did it lead to interesting results in the original study.*

#### *Method Selection*

*In terms of estimation methods, I used constrained SEM maximum-likelihood (SEM-ML) and unweighted-least-squares estimation (SEM-ULS), so that loadings and variance parameters were given the constraints that they had to be positive and larger than 0.01.
Additionally, I implemented local-SAM (LSAM) and global-SAM (GSAM) estimation, in both maximum-likelihood (LSAM-ML/ GSAM-ML), and unweighted-least-squares estimation (GSAM-ML/ GSAM-ULS) contexts.
Exceptions were studies 1b, 4 and 4a, where only LSAM was investigated, as results did not really differ between the two different SAM-methods [@robitzsch_comparing_2022].*

#### *Performance Measures*

*I calculated the bias and RMSE of the estimated factor correlations in all studies, as well as the standard deviation of the one factor correlation present in Studies 1,2 and 3.
For the type of bias calculated, I oriented on @robitzsch_comparing_2022, besides in Study 1b.
Thus, I calculated average relative bias in Studies 1, 2 and 3, and average absolute bias in Studies 1b, 4 and 4a.
In Study 1b, I took the absolute value to see if negative and positive biases canceled each other out in the original study for conditions with lower phi values.
In addition to what was done in @robitzsch_comparing_2022, I calculated confidence intervals for the bias estimates, but omitted them in the results tables for presentation purposes.
The exact computation of the performance measures is detailed in the simulation scripts and results.pdf file in my sub-folder of the Github repository.
I did not include a detailed mechanism to capture model convergence as detailed in the first substantive research question.
As @robitzsch_comparing_2022 argued in their paper, and was shown already in other simulations, using constrained maximum likelihood estimation should resolve convergence issues of classical maximum likelihood estimation in smaller samples [@ludtke_comparison_2021; @ulitzsch_alleviating_2023].
I did include, however, a mechanism to track the total number of warnings for each estimation and compare it to the total number of estimations as a sanity check.*

#### *Software*

*All analyses were conducted in R [@r_core_team_r_2023].
I used the packages lavaan, purrr, tidyverse, furrr to conduct the simulations, as well as knitr and kableExtra for presenting the results [@rosseel_lavaan_2012; @purrr; @wickham_welcome_2019; @davis_furrr_2022; @knitr; @zhu_kableextra_2024].*

#### *Analysis and Interpretation plan*

*For the interpretation of results, I oriented on cut-offs that were used in the original paper by @robitzsch_comparing_2022.
For bias, I interpreted differences of 0.05 or higher as substantial.
For SD, I explicitly mentioned percentage reductions of more or equal to 5%.
For RMSE, the same interpretation was used for differences of 0.03 or higher. 
The simulation was repeated 1500 times for each Study.*
